{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a261bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\PMLS\\ml\\fyp\\SHAHID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29cef70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stlf_torch_kit import  DataLoadeing\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, time\n",
    "from stlf_torch_kit import univariate_multi_step\n",
    "from stlf_torch_kit import SaveBestModel, PlotLossCurves, LoadModel, train, TestModel, BatchGenerator, results\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffabf9c1-c91d-476c-bb1e-90968a07d31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc31f46",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2a9dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7884, 16), (438, 16), (438, 16))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dataset =r'C:\\Users\\PMLS\\shahid (ML-lab)\\final_data' #Edit\n",
    "path_tr = os.path.join(path_dataset, 'train_data1.csv')\n",
    "df_tr = pd.read_csv(path_tr)\n",
    "train_set = df_tr.values\n",
    "path_v = os.path.join(path_dataset, 'validation_data1.csv')\n",
    "df_v = pd.read_csv(path_v)\n",
    "validation_set = df_v.values\n",
    "path_te = os.path.join(path_dataset, 'test_data1.csv')\n",
    "df_te = pd.read_csv(path_te)\n",
    "test_set = df_te.values \n",
    "\n",
    "#path_scaler = os.path.join(path_dataset, 'AEP_Scaler.pkl')\n",
    "#scaler         = pickle.load(open(path_scaler, 'rb'))\n",
    "\n",
    "train_set.shape, validation_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293ad9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Consumed 0.019933462142944336 sec\n"
     ]
    }
   ],
   "source": [
    "time_steps=24 #look back or sequence length, lag, window size #Edit\n",
    "target_len = 1 #how much steps do you wana forecast #Edit\n",
    "start = time.time()\n",
    "train_X , train_y = univariate_multi_step(train_set, time_steps, target_col=0,target_len=target_len)\n",
    "validation_X, validation_y = univariate_multi_step(validation_set, time_steps, target_col=0,target_len=target_len)\n",
    "test_X, test_y = univariate_multi_step(test_set, time_steps, target_col=0,target_len=target_len)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc241223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7859, 24, 16), (7859, 1), (413, 24, 16), (413, 1), (413, 24, 16), (413, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,train_y.shape,validation_X.shape, validation_y.shape,test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52558d",
   "metadata": {},
   "source": [
    "# Proposed Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28011352",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8487fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# major edit\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lstm = nn.LSTM(14, 20, 1, batch_first=True).to(self.device) # num-features, node/units, num-layers\n",
    "        self.fc = nn.Linear(20, 1).to(self.device) #(in,out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x) # _=(h,c)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e842fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN1DModel                               [64, 1]                   --\n",
      "├─Conv1d: 1-1                            [64, 32, 22]              1,376\n",
      "├─Linear: 1-2                            [64, 1]                   705\n",
      "==========================================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.98\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 0.36\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.46\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model3 = LSTMModel()\n",
    "print(summary(model, input_size=(64, 24, 14)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533489a",
   "metadata": {},
   "source": [
    "#### CNN\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse; width: 100%;\">\n",
    "    <thead>\n",
    "        <tr style=\"background-color: #f2f2f2;\">\n",
    "            <th style=\"border: 1px solid black; padding: 8px;\">Layer</th>\n",
    "            <th style=\"border: 1px solid black; padding: 8px;\">Expected Input Shape</th>\n",
    "            <th style=\"border: 1px solid black; padding: 8px;\">Common Adjustments Needed</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">Conv1d</td>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">(batch_size, channels, sequence_length)</td>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">Permute input from (batch, seq, feat) to (batch, feat, seq)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">LSTM</td>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">(batch_size, sequence_length, features)</td>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">No permutation if batch_first=True</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b7fa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.conv1 = nn.Conv1d(in_channels=14, out_channels=32, kernel_size=3).to(self.device)\n",
    "        self.fc = nn.Linear(32*22, 1).to(self.device) #32 channels ao 22 features dy chy kernel size 3 na bad kam shwal\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv1(x))  \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        out = self.fc(x) \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be5e53e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN1DModel                               [64, 1]                   --\n",
      "├─Conv1d: 1-1                            [64, 32, 22]              1,376\n",
      "├─Linear: 1-2                            [64, 1]                   705\n",
      "==========================================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.98\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 0.36\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.46\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model1 = CNN1DModel()\n",
    "print(summary(model1, input_size=(64, 24, 14)))\n",
    "# summary(model, input_size=(64, 24, 1), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2b859f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "class ProbSparseAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=False, factor=5, scale=None, attention_dropout=0.1):\n",
    "        super(ProbSparseAttention, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def _prob_QK(self, Q, K, sample_k, n_top):\n",
    "        B, H, L_K, E = K.shape\n",
    "        _, _, L_Q, _ = Q.shape\n",
    "\n",
    "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
    "        index_sample = torch.randint(L_K, (L_Q, sample_k))\n",
    "        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
    "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n",
    "\n",
    "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
    "        M_top = M.topk(n_top, sorted=False)[1]\n",
    "\n",
    "        Q_reduce = Q[torch.arange(B)[:, None, None],\n",
    "                    torch.arange(H)[None, :, None],\n",
    "                    M_top, :]\n",
    "        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1))\n",
    "        return Q_K, M_top\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask=None):\n",
    "        B, L_Q, H, D = queries.shape\n",
    "        _, L_K, _, _ = keys.shape\n",
    "\n",
    "        queries = queries.transpose(1, 2)  # [B, H, L_Q, D]\n",
    "        keys = keys.transpose(1, 2)       # [B, H, L_K, D]\n",
    "        values = values.transpose(1, 2)   # [B, H, L_K, D]\n",
    "\n",
    "        U_part = min(self.factor * np.ceil(np.log(L_K)).astype(int), L_K)\n",
    "        u = min(self.factor * np.ceil(np.log(L_Q)).astype(int), L_Q)\n",
    "        \n",
    "        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u)\n",
    "\n",
    "        scale = self.scale or 1./sqrt(D)\n",
    "        scores_top = scores_top * scale\n",
    "\n",
    "        attn = torch.softmax(scores_top, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        context = torch.matmul(attn, values)  # [B, H, u, D]\n",
    "        \n",
    "        output = torch.zeros_like(queries).to(queries.device)\n",
    "        output[torch.arange(B)[:, None, None],\n",
    "               torch.arange(H)[None, :, None],\n",
    "               index, :] = context\n",
    "        return output.transpose(1, 2).contiguous(), attn\n",
    "\n",
    "class InformerSTLF(nn.Module):\n",
    "    def __init__(self, enc_in=21, d_model=128, d_ff=256, n_heads=8, e_layers=3, dropout=0.2):\n",
    "        super(InformerSTLF, self).__init__()\n",
    "        self.n_heads = n_heads  # Store as class attribute\n",
    "        \n",
    "        # Input Embedding\n",
    "        self.enc_embedding = nn.Sequential(\n",
    "            nn.Linear(enc_in, d_model//2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model//2, d_model)\n",
    "        )\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 24, d_model))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # ConvLayer without downsampling\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(d_model, d_model, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Encoder Layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                ProbSparseAttention(mask_flag=False, factor=5, scale=None, attention_dropout=dropout),\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(d_model, d_ff),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(dropout),\n",
    "                    nn.Linear(d_ff, d_model)\n",
    "                ),\n",
    "                nn.LayerNorm(d_model)\n",
    "            ]) for _ in range(e_layers)\n",
    "        ])\n",
    "        \n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(d_model//2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch_size, 24, 21]\n",
    "        x = self.enc_embedding(x) + self.pos_embedding\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # ConvLayer (no length reduction)\n",
    "        x_conv = x.permute(0, 2, 1)  # [B, D, L]\n",
    "        x_conv = self.conv(x_conv)\n",
    "        x = x + x_conv.permute(0, 2, 1)  # Residual connection\n",
    "        \n",
    "        # Encoder\n",
    "        for attn, norm1, ff, norm2 in self.encoder_layers:\n",
    "            # Attention Block\n",
    "            residual = x\n",
    "            x = x.unsqueeze(1).expand(-1, self.n_heads, -1, -1)  # Now using stored n_heads\n",
    "            x, _ = attn(x, x, x)\n",
    "            x = x.mean(dim=1)  # Average over heads\n",
    "            x = norm1(x + residual)\n",
    "            \n",
    "            # Feed Forward Block\n",
    "            residual = x\n",
    "            x = ff(x)\n",
    "            x = norm2(x + residual)\n",
    "        \n",
    "        # Final Prediction\n",
    "        x = x[:, -1, :]  # Last timestep\n",
    "        return self.projection(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "61459259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "InformerSTLF                             [64, 1]                   3,072\n",
      "├─Sequential: 1-1                        [64, 24, 128]             --\n",
      "│    └─Linear: 2-1                       [64, 24, 64]              960\n",
      "│    └─GELU: 2-2                         [64, 24, 64]              --\n",
      "│    └─Linear: 2-3                       [64, 24, 128]             8,320\n",
      "├─Dropout: 1-2                           [64, 24, 128]             --\n",
      "├─Sequential: 1-3                        [64, 128, 24]             --\n",
      "│    └─Conv1d: 2-4                       [64, 128, 24]             49,280\n",
      "│    └─BatchNorm1d: 2-5                  [64, 128, 24]             256\n",
      "│    └─GELU: 2-6                         [64, 128, 24]             --\n",
      "├─ModuleList: 1-4                        --                        --\n",
      "│    └─ModuleList: 2-7                   --                        --\n",
      "│    │    └─ProbSparseAttention: 3-1     [64, 8, 24, 128]          --\n",
      "│    │    └─LayerNorm: 3-2               [64, 24, 128]             256\n",
      "│    │    └─Sequential: 3-3              [64, 24, 128]             65,920\n",
      "│    │    └─LayerNorm: 3-4               [64, 24, 128]             256\n",
      "│    └─ModuleList: 2-8                   --                        --\n",
      "│    │    └─ProbSparseAttention: 3-5     [64, 8, 24, 128]          --\n",
      "│    │    └─LayerNorm: 3-6               [64, 24, 128]             256\n",
      "│    │    └─Sequential: 3-7              [64, 24, 128]             65,920\n",
      "│    │    └─LayerNorm: 3-8               [64, 24, 128]             256\n",
      "│    └─ModuleList: 2-9                   --                        --\n",
      "│    │    └─ProbSparseAttention: 3-9     [64, 8, 24, 128]          --\n",
      "│    │    └─LayerNorm: 3-10              [64, 24, 128]             256\n",
      "│    │    └─Sequential: 3-11             [64, 24, 128]             65,920\n",
      "│    │    └─LayerNorm: 3-12              [64, 24, 128]             256\n",
      "├─Sequential: 1-5                        [64, 1]                   --\n",
      "│    └─Linear: 2-10                      [64, 64]                  8,256\n",
      "│    └─ReLU: 2-11                        [64, 64]                  --\n",
      "│    └─Dropout: 2-12                     [64, 64]                  --\n",
      "│    └─Linear: 2-13                      [64, 1]                   65\n",
      "==========================================================================================\n",
      "Total params: 269,505\n",
      "Trainable params: 269,505\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 89.59\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 29.13\n",
      "Params size (MB): 1.07\n",
      "Estimated Total Size (MB): 30.28\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model7 = InformerSTLF(\n",
    "    enc_in=14,          # Input features\n",
    "    d_model=128,        # Model dimension\n",
    "    d_ff=256,           # Feed-forward dimension\n",
    "    n_heads=8,          # Attention heads\n",
    "    e_layers=3,         # Encoder layers\n",
    "    dropout=0.2         # Dropout rate\n",
    ")\n",
    "\n",
    "# Check summary\n",
    "print(summary(model7, input_size=(64, 24, 14)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9a813",
   "metadata": {},
   "source": [
    "#### Mostly Cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1912c815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4ad8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=24*14):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5656de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNLSTMModel                             [32, 1]                   --\n",
      "├─Conv1d: 1-1                            [32, 64, 22]              2,752\n",
      "├─LSTM: 1-2                              [32, 22, 50]              64,000\n",
      "├─Linear: 1-3                            [32, 20]                  1,020\n",
      "├─Linear: 1-4                            [32, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 67,793\n",
      "Trainable params: 67,793\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 47.03\n",
      "==========================================================================================\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.65\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 0.96\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create and summarize the model\n",
    "model6 = MLP(input_size=24*14)\n",
    "print(summary(model, input_size=(32, 24, 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d35752a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOSTLY_CITED1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lstm = nn.LSTM(14, 20, 2, batch_first=True).to(self.device)\n",
    "        self.fc = nn.Linear(20, 1).to(self.device) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x) # _=(h,c)\n",
    "        out = torch.sigmoid(self.fc(out[:, -1, :]) )\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee7746cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOSTLY_CITED(nn.Module):\n",
    "    def __init__(self, input_size=16, hidden_size=20, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Move all parameters to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Move input to same device as model\n",
    "        x = x.to(self.device)\n",
    "        out, _ = self.lstm(x)  # out shape: (batch, seq_len, hidden_size)\n",
    "        out = self.fc(out[:, -1, :])  # Take last timestep\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaf03889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MOSTLY_CITED                             [32, 1]                   --\n",
      "├─LSTM: 1-1                              [32, 24, 20]              6,400\n",
      "├─Linear: 1-2                            [32, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 6,421\n",
      "Trainable params: 6,421\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 4.92\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.20\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model1 = MOSTLY_CITED()\n",
    "print(summary(model1, input_size=(32, 24, 16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "df67fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels=14, time_steps=24):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=16, kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(16*(time_steps-2), 1)  # -2 because of two conv layers with kernel_size=2\n",
    "        \n",
    "        # Move model to appropriate device\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        # PyTorch expects (batch, channels, seq_len) for Conv1d\n",
    "        x = x.permute(0, 2, 1)  # Change from (batch, seq_len, channels) to (batch, channels, seq_len)\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15ad4f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNLSTMModel                             [32, 1]                   --\n",
      "├─Conv1d: 1-1                            [32, 64, 22]              2,752\n",
      "├─LSTM: 1-2                              [32, 22, 50]              64,000\n",
      "├─Linear: 1-3                            [32, 20]                  1,020\n",
      "├─Linear: 1-4                            [32, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 67,793\n",
      "Trainable params: 67,793\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 47.03\n",
      "==========================================================================================\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.65\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 0.96\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model5 = CNN(input_channels=14, time_steps=24)\n",
    "print(summary(model5, input_size=(32, 24, 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33f8f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=16, hidden_size1=8, hidden_size2=20):\n",
    "        super().__init__()\n",
    "        self.rnn1 = nn.RNN(input_size=input_size, \n",
    "                          hidden_size=hidden_size1,\n",
    "                          batch_first=True,\n",
    "                          nonlinearity='relu')\n",
    "        self.rnn2 = nn.RNN(input_size=hidden_size1,\n",
    "                          hidden_size=hidden_size2,\n",
    "                          batch_first=True,\n",
    "                          nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size2, 1)\n",
    "        \n",
    "        # Move model to appropriate device\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        # First RNN layer (returns all sequences)\n",
    "        x, _ = self.rnn1(x)\n",
    "        # Second RNN layer (returns only last output)\n",
    "        x, _ = self.rnn2(x)\n",
    "        # Take the last time step's output\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6e54011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "RNN                                      [32, 1]                   --\n",
      "├─RNN: 1-1                               [32, 24, 8]               208\n",
      "├─RNN: 1-2                               [32, 24, 20]              600\n",
      "├─Linear: 1-3                            [32, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 829\n",
      "Trainable params: 829\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.62\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.17\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.22\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model2 = RNN(input_size=16)\n",
    "print(summary(model2, input_size=(32, 24, 16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f780774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.conv1 = nn.Conv1d(in_channels=14, out_channels=64, kernel_size=3).to(self.device)\n",
    "       \n",
    "        self.lstm = nn.LSTM(64, 50, 3, batch_first=True).to(self.device)\n",
    "        self.fc = nn.Linear(50, 20).to(self.device) \n",
    "        self.fc1 = nn.Linear(20, 1).to(self.device) \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x) # _=(h,c)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.fc1(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e71b034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNLSTMModel                             [64, 1]                   --\n",
      "├─Conv1d: 1-1                            [64, 64, 22]              2,752\n",
      "├─LSTM: 1-2                              [64, 22, 50]              64,000\n",
      "├─Linear: 1-3                            [64, 20]                  1,020\n",
      "├─Linear: 1-4                            [64, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 67,793\n",
      "Trainable params: 67,793\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 94.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 1.65\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model4 = CNNLSTMModel()\n",
    "print(summary(model4, input_size=(64, 24, 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c44873a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMForecastModel(nn.Module):\n",
    "    def __init__(self, time_steps, num_features):\n",
    "        super(LSTMForecastModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=num_features, hidden_size=8, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=8, hidden_size=20, batch_first=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(20, 1)  # final LSTM layer output size is 20\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, time_steps, num_features]\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = x[:, -1, :]  # Take the last time step output\n",
    "        x = self.flatten(x)\n",
    "        out = self.fc(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05f09c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LSTMForecastModel                        [64, 1]                   --\n",
      "├─LSTM: 1-1                              [64, 24, 8]               832\n",
      "├─LSTM: 1-2                              [64, 24, 20]              2,400\n",
      "├─Flatten: 1-3                           [64, 20]                  --\n",
      "├─Linear: 1-4                            [64, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 3,253\n",
      "Trainable params: 3,253\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 4.97\n",
      "==========================================================================================\n",
      "Input size (MB): 0.10\n",
      "Forward/backward pass size (MB): 0.34\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.46\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "time_steps = 24\n",
    "num_features = 16\n",
    "# Instantiate the model\n",
    "model8 = LSTMForecastModel(time_steps, num_features)\n",
    "print(summary(model8, input_size=(64, 24, 16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7491daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659def4",
   "metadata": {},
   "source": [
    "# instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2dbb6ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMForecastModel(\n",
       "  (lstm1): LSTM(16, 8, batch_first=True)\n",
       "  (lstm2): LSTM(8, 20, batch_first=True)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf1f740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MOSTLY_CITED()\n",
    "model=LSTMForecastModel(time_steps, num_features)\n",
    "#model = RNN(input_size=16)\n",
    "criterion = nn.MSELoss() #Edit, don't change\n",
    "\n",
    "save_best_model = SaveBestModel()\n",
    "Plot_Loss=PlotLossCurves()\n",
    "load_model=LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a217f",
   "metadata": {},
   "source": [
    "# Learning Rate & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9867523",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001 # Edit\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b55ecf",
   "metadata": {},
   "source": [
    "# Check Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53206b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cpu\n"
     ]
    }
   ],
   "source": [
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device\n",
    "device = get_model_device(model)\n",
    "print(\"Model is on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779171af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8fafebb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa963e",
   "metadata": {},
   "source": [
    "#### Path & other Stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3924df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "num_epochs = 50#Edit\n",
    "best_model_path=r'C:\\Users\\PMLS\\shahid (ML-lab)\\project_result'+str('\\\\') #Edit\n",
    "fig_path=r'C:\\Users\\PMLS\\shahid (ML-lab)\\project_result' #Edit\n",
    "train_data_loader, validation_data_loader, test_data_loader = DataLoadeing(train_X ,\n",
    "                                                                           train_y, \n",
    "                                                                           validation_X, \n",
    "                                                                           validation_y, \n",
    "                                                                           test_X, \n",
    "                                                                           test_y, \n",
    "                                                                           batch_size=32) #Batch_Size Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460874b",
   "metadata": {},
   "source": [
    "#### Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b17e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # Edit, for Now Don't  Change\n",
    "save_best_model = SaveBestModel()\n",
    "Plot_Loss=PlotLossCurves()\n",
    "load_model=LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bee91",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b37aa742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [246/246], Training Loss: 0.0600\n",
      "Epoch [1/50], Step [13/13], Val Loss: 0.0596\n",
      "\n",
      "Saving best model for epoch: 1\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\1best_model.pth\n",
      "Epoch [2/50], Step [246/246], Training Loss: 0.0387\n",
      "Epoch [2/50], Step [13/13], Val Loss: 0.0572\n",
      "\n",
      "Saving best model for epoch: 2\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\2best_model.pth\n",
      "Epoch [3/50], Step [246/246], Training Loss: 0.0368\n",
      "Epoch [3/50], Step [13/13], Val Loss: 0.0555\n",
      "\n",
      "Saving best model for epoch: 3\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\3best_model.pth\n",
      "Epoch [4/50], Step [246/246], Training Loss: 0.0347\n",
      "Epoch [4/50], Step [13/13], Val Loss: 0.0542\n",
      "\n",
      "Saving best model for epoch: 4\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\4best_model.pth\n",
      "Epoch [5/50], Step [246/246], Training Loss: 0.0323\n",
      "Epoch [5/50], Step [13/13], Val Loss: 0.0539\n",
      "\n",
      "Saving best model for epoch: 5\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\5best_model.pth\n",
      "Epoch [6/50], Step [246/246], Training Loss: 0.0295\n",
      "Epoch [6/50], Step [13/13], Val Loss: 0.0532\n",
      "\n",
      "Saving best model for epoch: 6\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\6best_model.pth\n",
      "Epoch [7/50], Step [246/246], Training Loss: 0.0269\n",
      "Epoch [7/50], Step [13/13], Val Loss: 0.0518\n",
      "\n",
      "Saving best model for epoch: 7\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\7best_model.pth\n",
      "Epoch [8/50], Step [246/246], Training Loss: 0.0251\n",
      "Epoch [8/50], Step [13/13], Val Loss: 0.0509\n",
      "\n",
      "Saving best model for epoch: 8\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\8best_model.pth\n",
      "Epoch [9/50], Step [246/246], Training Loss: 0.0241\n",
      "Epoch [9/50], Step [13/13], Val Loss: 0.0508\n",
      "\n",
      "Saving best model for epoch: 9\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\9best_model.pth\n",
      "Epoch [10/50], Step [246/246], Training Loss: 0.0236\n",
      "Epoch [10/50], Step [13/13], Val Loss: 0.0509\n",
      "Epoch [11/50], Step [246/246], Training Loss: 0.0233\n",
      "Epoch [11/50], Step [13/13], Val Loss: 0.0508\n",
      "\n",
      "Saving best model for epoch: 11\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\11best_model.pth\n",
      "Epoch [12/50], Step [246/246], Training Loss: 0.0231\n",
      "Epoch [12/50], Step [13/13], Val Loss: 0.0506\n",
      "\n",
      "Saving best model for epoch: 12\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\12best_model.pth\n",
      "Epoch [13/50], Step [246/246], Training Loss: 0.0229\n",
      "Epoch [13/50], Step [13/13], Val Loss: 0.0504\n",
      "\n",
      "Saving best model for epoch: 13\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\13best_model.pth\n",
      "Epoch [14/50], Step [246/246], Training Loss: 0.0228\n",
      "Epoch [14/50], Step [13/13], Val Loss: 0.0502\n",
      "\n",
      "Saving best model for epoch: 14\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\14best_model.pth\n",
      "Epoch [15/50], Step [246/246], Training Loss: 0.0227\n",
      "Epoch [15/50], Step [13/13], Val Loss: 0.0501\n",
      "\n",
      "Saving best model for epoch: 15\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\15best_model.pth\n",
      "Epoch [16/50], Step [246/246], Training Loss: 0.0226\n",
      "Epoch [16/50], Step [13/13], Val Loss: 0.0500\n",
      "\n",
      "Saving best model for epoch: 16\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\16best_model.pth\n",
      "Epoch [17/50], Step [246/246], Training Loss: 0.0225\n",
      "Epoch [17/50], Step [13/13], Val Loss: 0.0499\n",
      "\n",
      "Saving best model for epoch: 17\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\17best_model.pth\n",
      "Epoch [18/50], Step [246/246], Training Loss: 0.0224\n",
      "Epoch [18/50], Step [13/13], Val Loss: 0.0498\n",
      "\n",
      "Saving best model for epoch: 18\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\18best_model.pth\n",
      "Epoch [19/50], Step [246/246], Training Loss: 0.0223\n",
      "Epoch [19/50], Step [13/13], Val Loss: 0.0497\n",
      "\n",
      "Saving best model for epoch: 19\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\19best_model.pth\n",
      "Epoch [20/50], Step [246/246], Training Loss: 0.0223\n",
      "Epoch [20/50], Step [13/13], Val Loss: 0.0496\n",
      "\n",
      "Saving best model for epoch: 20\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\20best_model.pth\n",
      "Epoch [21/50], Step [246/246], Training Loss: 0.0222\n",
      "Epoch [21/50], Step [13/13], Val Loss: 0.0495\n",
      "\n",
      "Saving best model for epoch: 21\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\21best_model.pth\n",
      "Epoch [22/50], Step [246/246], Training Loss: 0.0221\n",
      "Epoch [22/50], Step [13/13], Val Loss: 0.0495\n",
      "\n",
      "Saving best model for epoch: 22\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\22best_model.pth\n",
      "Epoch [23/50], Step [246/246], Training Loss: 0.0221\n",
      "Epoch [23/50], Step [13/13], Val Loss: 0.0494\n",
      "\n",
      "Saving best model for epoch: 23\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\23best_model.pth\n",
      "Epoch [24/50], Step [246/246], Training Loss: 0.0220\n",
      "Epoch [24/50], Step [13/13], Val Loss: 0.0493\n",
      "\n",
      "Saving best model for epoch: 24\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\24best_model.pth\n",
      "Epoch [25/50], Step [246/246], Training Loss: 0.0219\n",
      "Epoch [25/50], Step [13/13], Val Loss: 0.0492\n",
      "\n",
      "Saving best model for epoch: 25\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\25best_model.pth\n",
      "Epoch [26/50], Step [246/246], Training Loss: 0.0219\n",
      "Epoch [26/50], Step [13/13], Val Loss: 0.0492\n",
      "\n",
      "Saving best model for epoch: 26\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\26best_model.pth\n",
      "Epoch [27/50], Step [246/246], Training Loss: 0.0218\n",
      "Epoch [27/50], Step [13/13], Val Loss: 0.0491\n",
      "\n",
      "Saving best model for epoch: 27\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\27best_model.pth\n",
      "Epoch [28/50], Step [246/246], Training Loss: 0.0217\n",
      "Epoch [28/50], Step [13/13], Val Loss: 0.0490\n",
      "\n",
      "Saving best model for epoch: 28\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\28best_model.pth\n",
      "Epoch [29/50], Step [246/246], Training Loss: 0.0217\n",
      "Epoch [29/50], Step [13/13], Val Loss: 0.0489\n",
      "\n",
      "Saving best model for epoch: 29\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\29best_model.pth\n",
      "Epoch [30/50], Step [246/246], Training Loss: 0.0216\n",
      "Epoch [30/50], Step [13/13], Val Loss: 0.0488\n",
      "\n",
      "Saving best model for epoch: 30\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\30best_model.pth\n",
      "Epoch [31/50], Step [246/246], Training Loss: 0.0215\n",
      "Epoch [31/50], Step [13/13], Val Loss: 0.0486\n",
      "\n",
      "Saving best model for epoch: 31\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\31best_model.pth\n",
      "Epoch [32/50], Step [246/246], Training Loss: 0.0215\n",
      "Epoch [32/50], Step [13/13], Val Loss: 0.0485\n",
      "\n",
      "Saving best model for epoch: 32\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\32best_model.pth\n",
      "Epoch [33/50], Step [246/246], Training Loss: 0.0214\n",
      "Epoch [33/50], Step [13/13], Val Loss: 0.0484\n",
      "\n",
      "Saving best model for epoch: 33\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\33best_model.pth\n",
      "Epoch [34/50], Step [246/246], Training Loss: 0.0213\n",
      "Epoch [34/50], Step [13/13], Val Loss: 0.0484\n",
      "\n",
      "Saving best model for epoch: 34\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\34best_model.pth\n",
      "Epoch [35/50], Step [246/246], Training Loss: 0.0213\n",
      "Epoch [35/50], Step [13/13], Val Loss: 0.0483\n",
      "\n",
      "Saving best model for epoch: 35\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\35best_model.pth\n",
      "Epoch [36/50], Step [246/246], Training Loss: 0.0212\n",
      "Epoch [36/50], Step [13/13], Val Loss: 0.0483\n",
      "\n",
      "Saving best model for epoch: 36\n",
      " at C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\36best_model.pth\n",
      "Epoch [37/50], Step [246/246], Training Loss: 0.0212\n",
      "Epoch [37/50], Step [13/13], Val Loss: 0.0483\n",
      "Epoch [38/50], Step [246/246], Training Loss: 0.0211\n",
      "Epoch [38/50], Step [13/13], Val Loss: 0.0484\n",
      "Epoch [39/50], Step [246/246], Training Loss: 0.0211\n",
      "Epoch [39/50], Step [13/13], Val Loss: 0.0485\n",
      "Epoch [40/50], Step [246/246], Training Loss: 0.0210\n",
      "Epoch [40/50], Step [13/13], Val Loss: 0.0486\n",
      "Epoch [41/50], Step [246/246], Training Loss: 0.0209\n",
      "Epoch [41/50], Step [13/13], Val Loss: 0.0486\n",
      "Epoch [42/50], Step [246/246], Training Loss: 0.0209\n",
      "Epoch [42/50], Step [13/13], Val Loss: 0.0487\n",
      "Epoch [43/50], Step [246/246], Training Loss: 0.0208\n",
      "Epoch [43/50], Step [13/13], Val Loss: 0.0489\n",
      "Epoch [44/50], Step [246/246], Training Loss: 0.0208\n",
      "Epoch [44/50], Step [13/13], Val Loss: 0.0493\n",
      "Epoch [45/50], Step [246/246], Training Loss: 0.0207\n",
      "Epoch [45/50], Step [13/13], Val Loss: 0.0494\n",
      "Epoch [46/50], Step [246/246], Training Loss: 0.0206\n",
      "Epoch [46/50], Step [13/13], Val Loss: 0.0490\n",
      "Epoch [47/50], Step [246/246], Training Loss: 0.0205\n",
      "Epoch [47/50], Step [13/13], Val Loss: 0.0491\n",
      "Epoch [48/50], Step [246/246], Training Loss: 0.0205\n",
      "Epoch [48/50], Step [13/13], Val Loss: 0.0497\n",
      "Epoch [49/50], Step [246/246], Training Loss: 0.0204\n",
      "Epoch [49/50], Step [13/13], Val Loss: 0.0502\n",
      "Epoch [50/50], Step [246/246], Training Loss: 0.0204\n",
      "Epoch [50/50], Step [13/13], Val Loss: 0.0505\n",
      "Time Consumed 5906.245846748352 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c897f0",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0f2d45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d8e071d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 0.0003\n",
      "Time Consumed 0.024692058563232422 sec\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "results() takes exactly 3 positional arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9472\\1950580188.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred_scaled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload_model_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time Consumed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_pred_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# MAPE, MAE, RMSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ml\\fyp\\SHAHID\\stlf_torch_kit.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mstlf_torch_kit.results\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: results() takes exactly 3 positional arguments (2 given)"
     ]
    }
   ],
   "source": [
    "load_model_path=r'C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\16best_model.pth' # Edit\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results( y_pred_scaled,test_y)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the original dataset (assuming you already have it)\n",
    "df = pd.read_csv(r'G:\\8TH SEMESTER\\MACHINE_LEARNING(T+L)\\LAB_ML\\OPENEND_LAB\\DATASET\\cleaned_non_shiftable_load_v2.csv')\n",
    "\n",
    "# Split data\n",
    "def split_data(df, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    total = len(df)\n",
    "    train_end = int(train_ratio * total)\n",
    "    val_end = train_end + int(val_ratio * total)\n",
    "    train_df = df.iloc[:train_end]\n",
    "    val_df = df.iloc[train_end:val_end]\n",
    "    test_df = df.iloc[val_end:]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = split_data(df)\n",
    "\n",
    "# STEP 1: Fit the scaler on training data's non_shiftable_load\n",
    "non_shiftable_scaler = MinMaxScaler()\n",
    "train_non_shiftable = train_df['non_shiftable_load'].values.reshape(-1, 1)\n",
    "non_shiftable_scaler.fit(train_non_shiftable)  # <<< THIS IS MANDATORY\n",
    "\n",
    "# STEP 2: Inverse transform the scaled values\n",
    "# test_y and y_pred_scaled must be in shape (n, 1)\n",
    "\n",
    "# Example placeholders (replace with your real scaled test values)\n",
    "# test_y = np.array([[0.23], [0.45], ...])\n",
    "# y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# Now use inverse_transform\n",
    "y_test_unscaled = non_shiftable_scaler.inverse_transform(test_y)\n",
    "y_pred          = non_shiftable_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Step 3: Error metrics\n",
    "MAE = np.mean(abs(y_pred - y_test_unscaled)) \n",
    "print('Mean Absolute Error (MAE): ' + str(np.round(MAE, 2)))\n",
    "\n",
    "MEDAE = np.median(abs(y_pred - y_test_unscaled))\n",
    "print('Median Absolute Error (MedAE): ' + str(np.round(MEDAE, 2)))\n",
    "\n",
    "MSE = np.square(np.subtract(y_pred, y_test_unscaled)).mean()\n",
    "print('Mean Squared Error (MSE): ' + str(np.round(MSE, 2)))\n",
    "\n",
    "RMSE = np.sqrt(np.mean(np.square(y_pred - y_test_unscaled)))\n",
    "print('Root Mean Squared Error (RMSE): ' + str(np.round(RMSE, 2)))\n",
    "\n",
    "MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print('Mean Absolute Percentage Error (MAPE): ' + str(np.round(MAPE, 2)) + ' %')\n",
    "\n",
    "MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print('Median Absolute Percentage Error (MDAPE): ' + str(np.round(MDAPE, 2)) + ' %')\n",
    "\n",
    "print('\\n\\ny_test_unscaled.shape= ', y_test_unscaled.shape)\n",
    "print('y_pred.shape= ', y_pred.shape)\n",
    "# MAPE, MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ed24f",
   "metadata": {},
   "source": [
    "# Fine Tunning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "42338ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "lr=0.003\n",
    "Batch_size = True #batch size maintained\n",
    "load_model_path=r'C:\\Users\\PMLS\\shahid (ML-lab)\\project_result\\19best_model.pth' # Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaffc7c",
   "metadata": {},
   "source": [
    "#### Load Model for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2d00f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 0.003\n"
     ]
    }
   ],
   "source": [
    "if Batch_size is True:\n",
    "    model_, optimizer, start_epoch= load_model(model, model_path=load_model_path,\n",
    "                               lr=lr,\n",
    "                               train_X=train_X,\n",
    "                               train_y=train_y,\n",
    "                               validation_X=validation_X,\n",
    "                               validation_y=validation_y,\n",
    "                               test_X=test_X,\n",
    "                               test_y=test_y)\n",
    "\n",
    "else:\n",
    "    model_, optimizer, start_epoch, train_data_loader, validation_data_loader, test_data_loader = load_model(model,model_path=load_model_path,\n",
    "                                                                                             lr=lr,\n",
    "                                                                                             Batch_Size=32,\n",
    "                                                                                             train_X=train_X,\n",
    "                                                                                             train_y=train_y,\n",
    "                                                                                             validation_X=validation_X,\n",
    "                                                                                             validation_y=validation_y,\n",
    "                                                                                             test_X=test_X,\n",
    "                                                                                             test_y=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3e7d8432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/69], Step [191/191], Training Loss: 0.0226\n",
      "Epoch [20/69], Step [54/54], Val Loss: 0.0252\n",
      "Epoch [21/69], Step [191/191], Training Loss: 0.0229\n",
      "Epoch [21/69], Step [54/54], Val Loss: 0.0250\n",
      "Epoch [22/69], Step [19/191], Training Loss: 0.0308\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9404\\1954758671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m       \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m       \u001b[0mvalidation_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m      load_model_epoch=start_epoch)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time Consumed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ml\\fyp\\SHAHID\\stlf_torch_kit.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mstlf_torch_kit.train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mll\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mll\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_)\n",
    "start = time.time()\n",
    "\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader,\n",
    "     load_model_epoch=start_epoch)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19971578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 0.0001\n",
      "Time Consumed 0.33310914039611816 sec\n",
      "Mean Absolute Error (MAE): 91.52\n",
      "Median Absolute Error (MedAE): 73.46\n",
      "Mean Squared Error (MSE): 14804.34\n",
      "Root Mean Squared Error (RMSE): 121.67\n",
      "Mean Absolute Percentage Error (MAPE): 0.62 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.51 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (12105, 1)\n",
      "y_pred.shape=  (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'D:\\chk6\\88best_model.pth'\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b5c72",
   "metadata": {},
   "source": [
    "# Fine Tunning 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8855adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 0.00001\n",
    "Batch_size=32\n",
    "load_model_path=r'D:\\chk6\\88best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1a0f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n"
     ]
    }
   ],
   "source": [
    "if Batch_size is True:\n",
    "    model_, optimizer, start_epoch= load_model(model, model_path=load_model_path,\n",
    "                               lr=lr,\n",
    "                               train_X=train_X,\n",
    "                               train_y=train_y,\n",
    "                               validation_X=validation_X,\n",
    "                               validation_y=validation_y,\n",
    "                               test_X=test_X,\n",
    "                               test_y=test_y)\n",
    "\n",
    "else:\n",
    "    model_, optimizer, start_epoch, train_data_loader, validation_data_loader, test_data_loader = load_model(model,model_path=load_model_path,\n",
    "                                                                                             lr=lr,\n",
    "                                                                                             Batch_Size=Batch_size,\n",
    "                                                                                             train_X=train_X,\n",
    "                                                                                             train_y=train_y,\n",
    "                                                                                             validation_X=validation_X,\n",
    "                                                                                             validation_y=validation_y,\n",
    "                                                                                             test_X=test_X,\n",
    "                                                                                             test_y=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfc79445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/108], Step [2653/2653], Training Loss: 0.0001\n",
      "Epoch [89/108], Step [758/758], Val Loss: 0.0001\n",
      "Epoch [90/108], Step [2653/2653], Training Loss: 0.0001\n",
      "Epoch [90/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 90\n",
      " at D:\\chk6\\90best_model.pth\n",
      "Epoch [91/108], Step [2653/2653], Training Loss: 0.0001\n",
      "Epoch [91/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 91\n",
      " at D:\\chk6\\91best_model.pth\n",
      "Epoch [92/108], Step [2653/2653], Training Loss: 0.0001\n",
      "Epoch [92/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 92\n",
      " at D:\\chk6\\92best_model.pth\n",
      "Epoch [93/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [93/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 93\n",
      " at D:\\chk6\\93best_model.pth\n",
      "Epoch [94/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [94/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 94\n",
      " at D:\\chk6\\94best_model.pth\n",
      "Epoch [95/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [95/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 95\n",
      " at D:\\chk6\\95best_model.pth\n",
      "Epoch [96/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [96/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 96\n",
      " at D:\\chk6\\96best_model.pth\n",
      "Epoch [97/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [97/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 97\n",
      " at D:\\chk6\\97best_model.pth\n",
      "Epoch [98/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [98/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 98\n",
      " at D:\\chk6\\98best_model.pth\n",
      "Epoch [99/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [99/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 99\n",
      " at D:\\chk6\\99best_model.pth\n",
      "Epoch [100/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [100/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 100\n",
      " at D:\\chk6\\100best_model.pth\n",
      "Epoch [101/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [101/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 101\n",
      " at D:\\chk6\\101best_model.pth\n",
      "Epoch [102/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [102/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 102\n",
      " at D:\\chk6\\102best_model.pth\n",
      "Epoch [103/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [103/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 103\n",
      " at D:\\chk6\\103best_model.pth\n",
      "Epoch [104/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [104/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 104\n",
      " at D:\\chk6\\104best_model.pth\n",
      "Epoch [105/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [105/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 105\n",
      " at D:\\chk6\\105best_model.pth\n",
      "Epoch [106/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [106/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 106\n",
      " at D:\\chk6\\106best_model.pth\n",
      "Epoch [107/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [107/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 107\n",
      " at D:\\chk6\\107best_model.pth\n",
      "Epoch [108/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [108/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 108\n",
      " at D:\\chk6\\108best_model.pth\n",
      "Time Consumed 252.91170525550842 sec\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_)\n",
    "start = time.time()\n",
    "\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader,\n",
    "     load_model_epoch=start_epoch)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "403a487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n",
      "Time Consumed 0.29328155517578125 sec\n",
      "Mean Absolute Error (MAE): 91.01\n",
      "Median Absolute Error (MedAE): 71.54\n",
      "Mean Squared Error (MSE): 14858.5\n",
      "Root Mean Squared Error (RMSE): 121.9\n",
      "Mean Absolute Percentage Error (MAPE): 0.62 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.5 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (12105, 1)\n",
      "y_pred.shape=  (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'D:\\chk6\\108best_model.pth'\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2db74c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "#lr = 0.0001\n",
    "Batch_size=32\n",
    "load_model_path=r'D:\\chk6\\108best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dab68625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n"
     ]
    }
   ],
   "source": [
    "if Batch_size is True:\n",
    "    model_, optimizer, start_epoch= load_model(model, model_path=load_model_path,\n",
    "                               lr=lr,\n",
    "                               train_X=train_X,\n",
    "                               train_y=train_y,\n",
    "                               validation_X=validation_X,\n",
    "                               validation_y=validation_y,\n",
    "                               test_X=test_X,\n",
    "                               test_y=test_y)\n",
    "\n",
    "else:\n",
    "    model_, optimizer, start_epoch, train_data_loader, validation_data_loader, test_data_loader = load_model(model,model_path=load_model_path,\n",
    "                                                                                             lr=lr,\n",
    "                                                                                             Batch_Size=Batch_size,\n",
    "                                                                                             train_X=train_X,\n",
    "                                                                                             train_y=train_y,\n",
    "                                                                                             validation_X=validation_X,\n",
    "                                                                                             validation_y=validation_y,\n",
    "                                                                                             test_X=test_X,\n",
    "                                                                                             test_y=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba9a314b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [109/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 109\n",
      " at D:\\chk6\\109best_model.pth\n",
      "Epoch [110/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [110/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 110\n",
      " at D:\\chk6\\110best_model.pth\n",
      "Epoch [111/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [111/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 111\n",
      " at D:\\chk6\\111best_model.pth\n",
      "Epoch [112/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [112/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 112\n",
      " at D:\\chk6\\112best_model.pth\n",
      "Epoch [113/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [113/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 113\n",
      " at D:\\chk6\\113best_model.pth\n",
      "Epoch [114/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [114/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 114\n",
      " at D:\\chk6\\114best_model.pth\n",
      "Epoch [115/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [115/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 115\n",
      " at D:\\chk6\\115best_model.pth\n",
      "Epoch [116/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [116/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 116\n",
      " at D:\\chk6\\116best_model.pth\n",
      "Epoch [117/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [117/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 117\n",
      " at D:\\chk6\\117best_model.pth\n",
      "Epoch [118/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [118/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 118\n",
      " at D:\\chk6\\118best_model.pth\n",
      "Epoch [119/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [119/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 119\n",
      " at D:\\chk6\\119best_model.pth\n",
      "Epoch [120/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [120/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 120\n",
      " at D:\\chk6\\120best_model.pth\n",
      "Epoch [121/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [121/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 121\n",
      " at D:\\chk6\\121best_model.pth\n",
      "Epoch [122/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [122/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 122\n",
      " at D:\\chk6\\122best_model.pth\n",
      "Epoch [123/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [123/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 123\n",
      " at D:\\chk6\\123best_model.pth\n",
      "Epoch [124/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [124/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 124\n",
      " at D:\\chk6\\124best_model.pth\n",
      "Epoch [125/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [125/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 125\n",
      " at D:\\chk6\\125best_model.pth\n",
      "Epoch [126/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [126/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 126\n",
      " at D:\\chk6\\126best_model.pth\n",
      "Epoch [127/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [127/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 127\n",
      " at D:\\chk6\\127best_model.pth\n",
      "Epoch [128/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [128/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 128\n",
      " at D:\\chk6\\128best_model.pth\n",
      "Epoch [129/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [129/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 129\n",
      " at D:\\chk6\\129best_model.pth\n",
      "Epoch [130/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [130/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 130\n",
      " at D:\\chk6\\130best_model.pth\n",
      "Epoch [131/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [131/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 131\n",
      " at D:\\chk6\\131best_model.pth\n",
      "Epoch [132/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [132/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 132\n",
      " at D:\\chk6\\132best_model.pth\n",
      "Epoch [133/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [133/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 133\n",
      " at D:\\chk6\\133best_model.pth\n",
      "Epoch [134/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [134/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 134\n",
      " at D:\\chk6\\134best_model.pth\n",
      "Epoch [135/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [135/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 135\n",
      " at D:\\chk6\\135best_model.pth\n",
      "Epoch [136/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [136/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 136\n",
      " at D:\\chk6\\136best_model.pth\n",
      "Epoch [137/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [137/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 137\n",
      " at D:\\chk6\\137best_model.pth\n",
      "Epoch [138/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [138/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 138\n",
      " at D:\\chk6\\138best_model.pth\n",
      "Epoch [139/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [139/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 139\n",
      " at D:\\chk6\\139best_model.pth\n",
      "Epoch [140/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [140/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 140\n",
      " at D:\\chk6\\140best_model.pth\n",
      "Epoch [141/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [141/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 141\n",
      " at D:\\chk6\\141best_model.pth\n",
      "Epoch [142/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [142/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 142\n",
      " at D:\\chk6\\142best_model.pth\n",
      "Epoch [143/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [143/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 143\n",
      " at D:\\chk6\\143best_model.pth\n",
      "Epoch [144/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [144/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 144\n",
      " at D:\\chk6\\144best_model.pth\n",
      "Epoch [145/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [145/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 145\n",
      " at D:\\chk6\\145best_model.pth\n",
      "Epoch [146/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [146/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 146\n",
      " at D:\\chk6\\146best_model.pth\n",
      "Epoch [147/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [147/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 147\n",
      " at D:\\chk6\\147best_model.pth\n",
      "Epoch [148/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [148/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 148\n",
      " at D:\\chk6\\148best_model.pth\n",
      "Time Consumed 570.459014415741 sec\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_)\n",
    "start = time.time()\n",
    "\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader,\n",
    "     load_model_epoch=start_epoch)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e08ead66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n",
      "Time Consumed 0.7108466625213623 sec\n",
      "Mean Absolute Error (MAE): 90.44\n",
      "Median Absolute Error (MedAE): 70.79\n",
      "Mean Squared Error (MSE): 14699.12\n",
      "Root Mean Squared Error (RMSE): 121.24\n",
      "Mean Absolute Percentage Error (MAPE): 0.62 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.49 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (12105, 1)\n",
      "y_pred.shape=  (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'D:\\chk6\\148best_model.pth'\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6930fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85d1b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "#lr = 0.00001\n",
    "Batch_size=32\n",
    "load_model_path=r'D:\\chk6\\148best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "261fc4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n"
     ]
    }
   ],
   "source": [
    "if Batch_size is True:\n",
    "    model_, optimizer, start_epoch= load_model(model, model_path=load_model_path,\n",
    "                               lr=lr,\n",
    "                               train_X=train_X,\n",
    "                               train_y=train_y,\n",
    "                               validation_X=validation_X,\n",
    "                               validation_y=validation_y,\n",
    "                               test_X=test_X,\n",
    "                               test_y=test_y)\n",
    "\n",
    "else:\n",
    "    model_, optimizer, start_epoch, train_data_loader, validation_data_loader, test_data_loader = load_model(model,model_path=load_model_path,\n",
    "                                                                                             lr=lr,\n",
    "                                                                                             Batch_Size=Batch_size,\n",
    "                                                                                             train_X=train_X,\n",
    "                                                                                             train_y=train_y,\n",
    "                                                                                             validation_X=validation_X,\n",
    "                                                                                             validation_y=validation_y,\n",
    "                                                                                             test_X=test_X,\n",
    "                                                                                             test_y=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52effded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [149/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 149\n",
      " at D:\\chk6\\149best_model.pth\n",
      "Epoch [150/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [150/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 150\n",
      " at D:\\chk6\\150best_model.pth\n",
      "Epoch [151/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [151/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 151\n",
      " at D:\\chk6\\151best_model.pth\n",
      "Epoch [152/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [152/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 152\n",
      " at D:\\chk6\\152best_model.pth\n",
      "Epoch [153/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [153/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 153\n",
      " at D:\\chk6\\153best_model.pth\n",
      "Epoch [154/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [154/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 154\n",
      " at D:\\chk6\\154best_model.pth\n",
      "Epoch [155/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [155/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 155\n",
      " at D:\\chk6\\155best_model.pth\n",
      "Epoch [156/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [156/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 156\n",
      " at D:\\chk6\\156best_model.pth\n",
      "Epoch [157/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [157/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 157\n",
      " at D:\\chk6\\157best_model.pth\n",
      "Epoch [158/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [158/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 158\n",
      " at D:\\chk6\\158best_model.pth\n",
      "Epoch [159/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [159/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 159\n",
      " at D:\\chk6\\159best_model.pth\n",
      "Epoch [160/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [160/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 160\n",
      " at D:\\chk6\\160best_model.pth\n",
      "Epoch [161/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [161/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 161\n",
      " at D:\\chk6\\161best_model.pth\n",
      "Epoch [162/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [162/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 162\n",
      " at D:\\chk6\\162best_model.pth\n",
      "Epoch [163/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [163/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 163\n",
      " at D:\\chk6\\163best_model.pth\n",
      "Epoch [164/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [164/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 164\n",
      " at D:\\chk6\\164best_model.pth\n",
      "Epoch [165/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [165/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 165\n",
      " at D:\\chk6\\165best_model.pth\n",
      "Epoch [166/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [166/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 166\n",
      " at D:\\chk6\\166best_model.pth\n",
      "Epoch [167/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [167/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 167\n",
      " at D:\\chk6\\167best_model.pth\n",
      "Epoch [168/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [168/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 168\n",
      " at D:\\chk6\\168best_model.pth\n",
      "Epoch [169/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [169/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 169\n",
      " at D:\\chk6\\169best_model.pth\n",
      "Epoch [170/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [170/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 170\n",
      " at D:\\chk6\\170best_model.pth\n",
      "Epoch [171/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [171/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 171\n",
      " at D:\\chk6\\171best_model.pth\n",
      "Epoch [172/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [172/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 172\n",
      " at D:\\chk6\\172best_model.pth\n",
      "Epoch [173/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [173/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 173\n",
      " at D:\\chk6\\173best_model.pth\n",
      "Epoch [174/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [174/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 174\n",
      " at D:\\chk6\\174best_model.pth\n",
      "Epoch [175/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [175/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 175\n",
      " at D:\\chk6\\175best_model.pth\n",
      "Epoch [176/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [176/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 176\n",
      " at D:\\chk6\\176best_model.pth\n",
      "Epoch [177/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [177/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 177\n",
      " at D:\\chk6\\177best_model.pth\n",
      "Epoch [178/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [178/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 178\n",
      " at D:\\chk6\\178best_model.pth\n",
      "Epoch [179/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [179/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 179\n",
      " at D:\\chk6\\179best_model.pth\n",
      "Epoch [180/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [180/188], Step [758/758], Val Loss: 0.0001\n",
      "Epoch [181/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [181/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 181\n",
      " at D:\\chk6\\181best_model.pth\n",
      "Epoch [182/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [182/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 182\n",
      " at D:\\chk6\\182best_model.pth\n",
      "Epoch [183/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [183/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 183\n",
      " at D:\\chk6\\183best_model.pth\n",
      "Epoch [184/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [184/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 184\n",
      " at D:\\chk6\\184best_model.pth\n",
      "Epoch [185/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [185/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 185\n",
      " at D:\\chk6\\185best_model.pth\n",
      "Epoch [186/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [186/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 186\n",
      " at D:\\chk6\\186best_model.pth\n",
      "Epoch [187/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [187/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 187\n",
      " at D:\\chk6\\187best_model.pth\n",
      "Epoch [188/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [188/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 188\n",
      " at D:\\chk6\\188best_model.pth\n",
      "Time Consumed 522.1760857105255 sec\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_)\n",
    "start = time.time()\n",
    "\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader,\n",
    "     load_model_epoch=start_epoch)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "989a1be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n",
      "Time Consumed 0.32709288597106934 sec\n",
      "Mean Absolute Error (MAE): 90.16\n",
      "Median Absolute Error (MedAE): 70.6\n",
      "Mean Squared Error (MSE): 14619.34\n",
      "Root Mean Squared Error (RMSE): 120.91\n",
      "Mean Absolute Percentage Error (MAPE): 0.61 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.49 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (12105, 1)\n",
      "y_pred.shape=  (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'D:\\chk6\\188best_model.pth'\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
