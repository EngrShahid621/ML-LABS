{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a261bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\SHAHID\\shahid\\SHAHID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29cef70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stlf_torch_kit import  DataLoadeing\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, time\n",
    "from stlf_torch_kit import univariate_multi_step\n",
    "from stlf_torch_kit import SaveBestModel, PlotLossCurves, LoadModel, train, TestModel, BatchGenerator, results\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24653722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your Excel file\n",
    "df = pd.read_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\cleaned_citylearn_data_all_outliers_handled.csv')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "#df = pd.read_csv(\"your_file.csv\")  # Replace with your actual file name\n",
    "\n",
    "# Keep only the 'non_shiftable_load' column\n",
    "df_filtered = df[[\"non_shiftable_load\"]]\n",
    "\n",
    "# Save the filtered dataframe to a new CSV\n",
    "df_filtered.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\Raw data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f9d15e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File 'non_shiftable_with_datetime.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\Raw data.csv')  # Replace with your actual file name\n",
    "\n",
    "# Step 2: Keep only the non_shiftable_load column\n",
    "df = df[[\"non_shiftable_load\"]]\n",
    "\n",
    "# Step 3: Generate hourly datetime range\n",
    "start_date = \"2022-08-01 01:00\"\n",
    "datetime_range = pd.date_range(start=start_date, periods=8760, freq='H')\n",
    "\n",
    "# Step 4: Add datetime column\n",
    "df[\"datetime\"] = datetime_range\n",
    "\n",
    "# Step 5: Reorder columns (datetime first)\n",
    "df = df[[\"datetime\", \"non_shiftable_load\"]]\n",
    "\n",
    "# Step 6: Save the new DataFrame\n",
    "df.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\non_shiftable_with_datetime.csv', index=False)\n",
    "\n",
    "print(\"✅ File 'non_shiftable_with_datetime.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09ce47c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final dataset saved as 'non_shiftable_with_time_features.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "# ---- Time Feature Base Class ---- #\n",
    "class TimeFeature:\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \"()\"\n",
    "\n",
    "# ---- Concrete Time Features ---- #\n",
    "class SecondOfMinute(TimeFeature):\n",
    "    def __call__(self, index): return index.dt.second / 59.0 - 0.5\n",
    "\n",
    "class MinuteOfHour(TimeFeature):\n",
    "    def __call__(self, index): return index.dt.minute / 59.0 - 0.5\n",
    "\n",
    "class HourOfDay(TimeFeature):\n",
    "    def __call__(self, index): return index.dt.hour / 23.0 - 0.5\n",
    "\n",
    "class DayOfWeek(TimeFeature):\n",
    "    def __call__(self, index): return index.dt.dayofweek / 6.0 - 0.5\n",
    "\n",
    "class DayOfMonth(TimeFeature):\n",
    "    def __call__(self, index): return (index.dt.day - 1) / 30.0 - 0.5\n",
    "\n",
    "class DayOfYear(TimeFeature):\n",
    "    def __call__(self, index): return (index.dt.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "class MonthOfYear(TimeFeature):\n",
    "    def __call__(self, index): return (index.dt.month - 1) / 11.0 - 0.5\n",
    "\n",
    "class WeekOfYear(TimeFeature):\n",
    "    def __call__(self, index): return (index.dt.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "# ---- Feature Extractor from Frequency String ---- #\n",
    "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [MinuteOfHour, HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Second: [SecondOfMinute, MinuteOfHour, HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    raise RuntimeError(f\"Unsupported frequency: {freq_str}\")\n",
    "\n",
    "# ---- Time Feature Wrapper ---- #\n",
    "def time_features(dates: pd.DataFrame, timeenc=1, freq='h'):\n",
    "    if timeenc == 0:\n",
    "        dates['month'] = dates['Datetime'].apply(lambda x: x.month)\n",
    "        dates['day'] = dates['Datetime'].apply(lambda x: x.day)\n",
    "        dates['weekday'] = dates['Datetime'].apply(lambda x: x.weekday())\n",
    "        dates['hour'] = dates['Datetime'].apply(lambda x: x.hour)\n",
    "        dates['minute'] = dates['Datetime'].apply(lambda x: x.minute)\n",
    "        dates['minute'] = dates['Datetime'].map(lambda x: x // 15)\n",
    "        freq_map = {\n",
    "            'y': [],\n",
    "            'm': ['month'],\n",
    "            'w': ['month'],\n",
    "            'd': ['month', 'day', 'weekday'],\n",
    "            'b': ['month', 'day', 'weekday'],\n",
    "            'h': ['month', 'day', 'weekday', 'hour'],\n",
    "            't': ['month', 'day', 'weekday', 'hour', 'minute'],\n",
    "        }\n",
    "        return dates[freq_map[freq.lower()]].values\n",
    "    elif timeenc == 1:\n",
    "        datetime_index = pd.to_datetime(dates['Datetime'])\n",
    "        return np.vstack([feat(datetime_index) for feat in time_features_from_frequency_str(freq)]).transpose(1, 0)\n",
    "\n",
    "# ---- Main: Load CSV and Apply Time Features ---- #\n",
    "# Step 1: Load your CSV (with non_shiftable_load column)\n",
    "df = pd.read_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\non_shiftable_with_datetime.csv')  # Replace with your actual CSV name\n",
    "\n",
    "# Step 2: Create datetime range and add to DataFrame\n",
    "start_date = \"2022-08-01 00:00\"\n",
    "datetime_range = pd.date_range(start=start_date, periods=len(df), freq='H')\n",
    "df['Datetime'] = datetime_range\n",
    "\n",
    "# Step 3: Extract time features\n",
    "time_feats = time_features(df[['Datetime']], timeenc=1, freq='h')\n",
    "\n",
    "# Step 4: Combine time features into DataFrame\n",
    "time_feat_names = ['hour_of_day', 'day_of_week', 'day_of_month', 'day_of_year']\n",
    "time_feat_df = pd.DataFrame(time_feats, columns=time_feat_names)\n",
    "\n",
    "# Step 5: Final dataset with non_shiftable_load + time features\n",
    "final_df = pd.concat([df[[\"Datetime\", \"non_shiftable_load\"]], time_feat_df], axis=1)\n",
    "\n",
    "# Step 6: Save the final DataFrame\n",
    "final_df.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\non_shiftable_with_time_features.csv', index=False)\n",
    "\n",
    "print(\"✅ Final dataset saved as 'non_shiftable_with_time_features.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9607ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Load scaled. Time features untouched. Files saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load dataset\n",
    "df = pd.read_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\non_shiftable_with_time_features.csv')\n",
    "\n",
    "# Step 2: Drop 'Datetime' column only\n",
    "df = df.drop(columns=[\"Datetime\"])\n",
    "\n",
    "# Step 3: Split into 90/5/5\n",
    "total_len = len(df)\n",
    "train_end = int(0.9 * total_len)\n",
    "val_end = int(0.95 * total_len)\n",
    "\n",
    "train_df = df.iloc[:train_end].copy()\n",
    "val_df = df.iloc[train_end:val_end].copy()\n",
    "test_df = df.iloc[val_end:].copy()\n",
    "\n",
    "# Step 4: Scale only 'non_shiftable_load'\n",
    "scaler = MinMaxScaler()\n",
    "train_df['non_shiftable_load'] = scaler.fit_transform(train_df[['non_shiftable_load']])\n",
    "val_df['non_shiftable_load'] = scaler.transform(val_df[['non_shiftable_load']])\n",
    "test_df['non_shiftable_load'] = scaler.transform(test_df[['non_shiftable_load']])\n",
    "\n",
    "# Step 5: Save results\n",
    "train_df.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\train.csv', index=False)\n",
    "val_df.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\validation.csv', index=False)\n",
    "test_df.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\test.csv', index=False)\n",
    "\n",
    "print(\"✅ Load scaled. Time features untouched. Files saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b01651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Columns removed and cleaned file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load your dataset\n",
    "df = pd.read_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\cleaned_citylearn_data_all_outliers_handled.csv')\n",
    "\n",
    "# Step 2: Define fixed columns to drop\n",
    "fixed_cols_to_drop = ['non_shiftable_load', 'day_type', 'hour', 'month']\n",
    "\n",
    "# Step 3: Dynamically find all columns containing 'predicted'\n",
    "predicted_cols_to_drop = [col for col in df.columns if 'predicted' in col]\n",
    "\n",
    "# Step 4: Combine all columns to drop\n",
    "all_cols_to_drop = fixed_cols_to_drop + predicted_cols_to_drop\n",
    "\n",
    "# Step 5: Drop those columns\n",
    "df_cleaned = df.drop(columns=all_cols_to_drop)\n",
    "\n",
    "# Step 6: Save cleaned dataset\n",
    "df_cleaned.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\features_without_predicted.csv', index=False)\n",
    "\n",
    "print(\"✅ Columns removed and cleaned file saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7193f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Files concatenated successfully and saved as final_combined_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "features_cleaned = pd.read_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\features_without_predicted.csv')\n",
    "full_with_time = pd.read_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\non_shiftable_with_time_features.csv')\n",
    "\n",
    "# Concatenate both DataFrames (side by side)\n",
    "df_final = pd.concat([ full_with_time.reset_index(drop=True),features_cleaned.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save the result\n",
    "df_final.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\final_combined_features.csv', index=False)\n",
    "\n",
    "print(\"✅ Files concatenated successfully and saved as final_combined_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "19cbf69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Scaled selected columns, kept time features unchanged, and saved all splits.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load dataset\n",
    "df = pd.read_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\final_combined_features.csv')  # Replace with correct file path\n",
    "\n",
    "# Step 2: Remove 'Datetime' column if exists\n",
    "if 'Datetime' in df.columns:\n",
    "    df = df.drop(columns=['Datetime'])\n",
    "\n",
    "# Step 3: Define non-scaled time feature columns\n",
    "non_scaled_cols = ['hour_of_day', 'day_of_week', 'day_of_month', 'day_of_year']\n",
    "\n",
    "# Step 4: Separate scaled and unscaled parts\n",
    "scaled_cols = [col for col in df.columns if col not in non_scaled_cols]\n",
    "df_scaled_part = df[scaled_cols]\n",
    "df_unscaled_part = df[non_scaled_cols]\n",
    "\n",
    "# Step 5: Split into 90%, 5%, 5%\n",
    "total_len = len(df)\n",
    "train_end = int(0.9 * total_len)\n",
    "val_end = int(0.95 * total_len)\n",
    "\n",
    "# Split both parts\n",
    "train_scaled = df_scaled_part.iloc[:train_end]\n",
    "val_scaled = df_scaled_part.iloc[train_end:val_end]\n",
    "test_scaled = df_scaled_part.iloc[val_end:]\n",
    "\n",
    "train_unscaled = df_unscaled_part.iloc[:train_end]\n",
    "val_unscaled = df_unscaled_part.iloc[train_end:val_end]\n",
    "test_unscaled = df_unscaled_part.iloc[val_end:]\n",
    "\n",
    "# Step 6: Apply MinMaxScaler only to scaled columns\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled_trans = scaler.fit_transform(train_scaled)\n",
    "val_scaled_trans = scaler.transform(val_scaled)\n",
    "test_scaled_trans = scaler.transform(test_scaled)\n",
    "\n",
    "# Step 7: Convert back to DataFrames\n",
    "train_final = pd.concat([\n",
    "    pd.DataFrame(train_scaled_trans, columns=scaled_cols).reset_index(drop=True),\n",
    "    train_unscaled.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "val_final = pd.concat([\n",
    "    pd.DataFrame(val_scaled_trans, columns=scaled_cols).reset_index(drop=True),\n",
    "    val_unscaled.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "test_final = pd.concat([\n",
    "    pd.DataFrame(test_scaled_trans, columns=scaled_cols).reset_index(drop=True),\n",
    "    test_unscaled.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Step 8: Save to CSV\n",
    "train_final.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\train1.csv', index=False)\n",
    "val_final.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\validation1.csv', index=False)\n",
    "test_final.to_csv(r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer\\test1.csv', index=False)\n",
    "\n",
    "print(\"✅ Done! Scaled selected columns, kept time features unchanged, and saved all splits.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffabf9c1-c91d-476c-bb1e-90968a07d31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ddb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc31f46",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4b2a9dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7884, 12), (438, 12), (438, 12))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dataset =r'C:\\Users\\SHAHID\\shahid (ML-lab)\\citylearn datset for informer' #Edit\n",
    "path_tr = os.path.join(path_dataset, 'train1.csv')\n",
    "df_tr = pd.read_csv(path_tr)\n",
    "train_set = df_tr.values\n",
    "path_v = os.path.join(path_dataset, 'validation1.csv')\n",
    "df_v = pd.read_csv(path_v)\n",
    "validation_set = df_v.values\n",
    "path_te = os.path.join(path_dataset, 'test1.csv')\n",
    "df_te = pd.read_csv(path_te)\n",
    "test_set = df_te.values \n",
    "\n",
    "path_scaler = os.path.join(path_dataset, 'scaler.pkl')\n",
    "scaler         = pickle.load(open(path_scaler, 'rb'))\n",
    "\n",
    "train_set.shape, validation_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "293ad9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Consumed 0.14592647552490234 sec\n"
     ]
    }
   ],
   "source": [
    "time_steps=24 #look back or sequence length, lag, window size #Edit\n",
    "target_len = 1 #how much steps do you wana forecast #Edit\n",
    "start = time.time()\n",
    "train_X , train_y = univariate_multi_step(train_set, time_steps, target_col=0,target_len=target_len)\n",
    "validation_X, validation_y = univariate_multi_step(validation_set, time_steps, target_col=0,target_len=target_len)\n",
    "test_X, test_y = univariate_multi_step(test_set, time_steps, target_col=0,target_len=target_len)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dc241223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7859, 24, 12), (7859, 1), (413, 24, 12), (413, 1), (413, 24, 12), (413, 1))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,train_y.shape,validation_X.shape, validation_y.shape,test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52558d",
   "metadata": {},
   "source": [
    "# Proposed Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28011352",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8487fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# major edit\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lstm = nn.LSTM(14, 20, 1, batch_first=True).to(self.device) # num-features, node/units, num-layers\n",
    "        self.fc = nn.Linear(20, 1).to(self.device) #(in,out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x) # _=(h,c)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e842fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN1DModel                               [64, 1]                   --\n",
      "├─Conv1d: 1-1                            [64, 32, 22]              1,376\n",
      "├─Linear: 1-2                            [64, 1]                   705\n",
      "==========================================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.98\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 0.36\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.46\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model3 = LSTMModel()\n",
    "print(summary(model, input_size=(64, 24, 14)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533489a",
   "metadata": {},
   "source": [
    "#### CNN\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse; width: 100%;\">\n",
    "    <thead>\n",
    "        <tr style=\"background-color: #f2f2f2;\">\n",
    "            <th style=\"border: 1px solid black; padding: 8px;\">Layer</th>\n",
    "            <th style=\"border: 1px solid black; padding: 8px;\">Expected Input Shape</th>\n",
    "            <th style=\"border: 1px solid black; padding: 8px;\">Common Adjustments Needed</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">Conv1d</td>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">(batch_size, channels, sequence_length)</td>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">Permute input from (batch, seq, feat) to (batch, feat, seq)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">LSTM</td>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">(batch_size, sequence_length, features)</td>\n",
    "            <td style=\"border: 1px solid black; padding: 8px;\">No permutation if batch_first=True</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b7fa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.conv1 = nn.Conv1d(in_channels=14, out_channels=32, kernel_size=3).to(self.device)\n",
    "        self.fc = nn.Linear(32*22, 1).to(self.device) #32 channels ao 22 features dy chy kernel size 3 na bad kam shwal\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv1(x))  \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        out = self.fc(x) \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be5e53e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN1DModel                               [64, 1]                   --\n",
      "├─Conv1d: 1-1                            [64, 32, 22]              1,376\n",
      "├─Linear: 1-2                            [64, 1]                   705\n",
      "==========================================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.98\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 0.36\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.46\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model1 = CNN1DModel()\n",
    "print(summary(model1, input_size=(64, 24, 14)))\n",
    "# summary(model, input_size=(64, 24, 1), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2b859f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "class ProbSparseAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=False, factor=5, scale=None, attention_dropout=0.1):\n",
    "        super(ProbSparseAttention, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def _prob_QK(self, Q, K, sample_k, n_top):\n",
    "        B, H, L_K, E = K.shape\n",
    "        _, _, L_Q, _ = Q.shape\n",
    "\n",
    "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
    "        index_sample = torch.randint(L_K, (L_Q, sample_k))\n",
    "        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
    "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n",
    "\n",
    "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
    "        M_top = M.topk(n_top, sorted=False)[1]\n",
    "\n",
    "        Q_reduce = Q[torch.arange(B)[:, None, None],\n",
    "                    torch.arange(H)[None, :, None],\n",
    "                    M_top, :]\n",
    "        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1))\n",
    "        return Q_K, M_top\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask=None):\n",
    "        B, L_Q, H, D = queries.shape\n",
    "        _, L_K, _, _ = keys.shape\n",
    "\n",
    "        queries = queries.transpose(1, 2)  # [B, H, L_Q, D]\n",
    "        keys = keys.transpose(1, 2)       # [B, H, L_K, D]\n",
    "        values = values.transpose(1, 2)   # [B, H, L_K, D]\n",
    "\n",
    "        U_part = min(self.factor * np.ceil(np.log(L_K)).astype(int), L_K)\n",
    "        u = min(self.factor * np.ceil(np.log(L_Q)).astype(int), L_Q)\n",
    "        \n",
    "        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u)\n",
    "\n",
    "        scale = self.scale or 1./sqrt(D)\n",
    "        scores_top = scores_top * scale\n",
    "\n",
    "        attn = torch.softmax(scores_top, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        context = torch.matmul(attn, values)  # [B, H, u, D]\n",
    "        \n",
    "        output = torch.zeros_like(queries).to(queries.device)\n",
    "        output[torch.arange(B)[:, None, None],\n",
    "               torch.arange(H)[None, :, None],\n",
    "               index, :] = context\n",
    "        return output.transpose(1, 2).contiguous(), attn\n",
    "\n",
    "class InformerSTLF(nn.Module):\n",
    "    def __init__(self, enc_in=21, d_model=128, d_ff=256, n_heads=8, e_layers=3, dropout=0.2):\n",
    "        super(InformerSTLF, self).__init__()\n",
    "        self.n_heads = n_heads  # Store as class attribute\n",
    "        \n",
    "        # Input Embedding\n",
    "        self.enc_embedding = nn.Sequential(\n",
    "            nn.Linear(enc_in, d_model//2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model//2, d_model)\n",
    "        )\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 24, d_model))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # ConvLayer without downsampling\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(d_model, d_model, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Encoder Layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                ProbSparseAttention(mask_flag=False, factor=5, scale=None, attention_dropout=dropout),\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(d_model, d_ff),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(dropout),\n",
    "                    nn.Linear(d_ff, d_model)\n",
    "                ),\n",
    "                nn.LayerNorm(d_model)\n",
    "            ]) for _ in range(e_layers)\n",
    "        ])\n",
    "        \n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(d_model//2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch_size, 24, 21]\n",
    "        x = self.enc_embedding(x) + self.pos_embedding\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # ConvLayer (no length reduction)\n",
    "        x_conv = x.permute(0, 2, 1)  # [B, D, L]\n",
    "        x_conv = self.conv(x_conv)\n",
    "        x = x + x_conv.permute(0, 2, 1)  # Residual connection\n",
    "        \n",
    "        # Encoder\n",
    "        for attn, norm1, ff, norm2 in self.encoder_layers:\n",
    "            # Attention Block\n",
    "            residual = x\n",
    "            x = x.unsqueeze(1).expand(-1, self.n_heads, -1, -1)  # Now using stored n_heads\n",
    "            x, _ = attn(x, x, x)\n",
    "            x = x.mean(dim=1)  # Average over heads\n",
    "            x = norm1(x + residual)\n",
    "            \n",
    "            # Feed Forward Block\n",
    "            residual = x\n",
    "            x = ff(x)\n",
    "            x = norm2(x + residual)\n",
    "        \n",
    "        # Final Prediction\n",
    "        x = x[:, -1, :]  # Last timestep\n",
    "        return self.projection(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "61459259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "InformerSTLF                             [64, 1]                   3,072\n",
      "├─Sequential: 1-1                        [64, 24, 128]             --\n",
      "│    └─Linear: 2-1                       [64, 24, 64]              960\n",
      "│    └─GELU: 2-2                         [64, 24, 64]              --\n",
      "│    └─Linear: 2-3                       [64, 24, 128]             8,320\n",
      "├─Dropout: 1-2                           [64, 24, 128]             --\n",
      "├─Sequential: 1-3                        [64, 128, 24]             --\n",
      "│    └─Conv1d: 2-4                       [64, 128, 24]             49,280\n",
      "│    └─BatchNorm1d: 2-5                  [64, 128, 24]             256\n",
      "│    └─GELU: 2-6                         [64, 128, 24]             --\n",
      "├─ModuleList: 1-4                        --                        --\n",
      "│    └─ModuleList: 2-7                   --                        --\n",
      "│    │    └─ProbSparseAttention: 3-1     [64, 8, 24, 128]          --\n",
      "│    │    └─LayerNorm: 3-2               [64, 24, 128]             256\n",
      "│    │    └─Sequential: 3-3              [64, 24, 128]             65,920\n",
      "│    │    └─LayerNorm: 3-4               [64, 24, 128]             256\n",
      "│    └─ModuleList: 2-8                   --                        --\n",
      "│    │    └─ProbSparseAttention: 3-5     [64, 8, 24, 128]          --\n",
      "│    │    └─LayerNorm: 3-6               [64, 24, 128]             256\n",
      "│    │    └─Sequential: 3-7              [64, 24, 128]             65,920\n",
      "│    │    └─LayerNorm: 3-8               [64, 24, 128]             256\n",
      "│    └─ModuleList: 2-9                   --                        --\n",
      "│    │    └─ProbSparseAttention: 3-9     [64, 8, 24, 128]          --\n",
      "│    │    └─LayerNorm: 3-10              [64, 24, 128]             256\n",
      "│    │    └─Sequential: 3-11             [64, 24, 128]             65,920\n",
      "│    │    └─LayerNorm: 3-12              [64, 24, 128]             256\n",
      "├─Sequential: 1-5                        [64, 1]                   --\n",
      "│    └─Linear: 2-10                      [64, 64]                  8,256\n",
      "│    └─ReLU: 2-11                        [64, 64]                  --\n",
      "│    └─Dropout: 2-12                     [64, 64]                  --\n",
      "│    └─Linear: 2-13                      [64, 1]                   65\n",
      "==========================================================================================\n",
      "Total params: 269,505\n",
      "Trainable params: 269,505\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 89.59\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 29.13\n",
      "Params size (MB): 1.07\n",
      "Estimated Total Size (MB): 30.28\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model7 = InformerSTLF(\n",
    "    enc_in=14,          # Input features\n",
    "    d_model=128,        # Model dimension\n",
    "    d_ff=256,           # Feed-forward dimension\n",
    "    n_heads=8,          # Attention heads\n",
    "    e_layers=3,         # Encoder layers\n",
    "    dropout=0.2         # Dropout rate\n",
    ")\n",
    "\n",
    "# Check summary\n",
    "print(summary(model7, input_size=(64, 24, 14)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9a813",
   "metadata": {},
   "source": [
    "#### Mostly Cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1912c815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4ad8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=24*14):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5656de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNLSTMModel                             [32, 1]                   --\n",
      "├─Conv1d: 1-1                            [32, 64, 22]              2,752\n",
      "├─LSTM: 1-2                              [32, 22, 50]              64,000\n",
      "├─Linear: 1-3                            [32, 20]                  1,020\n",
      "├─Linear: 1-4                            [32, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 67,793\n",
      "Trainable params: 67,793\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 47.03\n",
      "==========================================================================================\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.65\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 0.96\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create and summarize the model\n",
    "model6 = MLP(input_size=24*14)\n",
    "print(summary(model, input_size=(32, 24, 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ba8038e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOSTLY_CITED1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lstm = nn.LSTM(14, 20, 2, batch_first=True).to(self.device)\n",
    "        self.fc = nn.Linear(20, 1).to(self.device) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x) # _=(h,c)\n",
    "        out = torch.sigmoid(self.fc(out[:, -1, :]) )\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee7746cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOSTLY_CITED(nn.Module):\n",
    "    def __init__(self, input_size=12, hidden_size=20, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Move all parameters to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Move input to same device as model\n",
    "        x = x.to(self.device)\n",
    "        out, _ = self.lstm(x)  # out shape: (batch, seq_len, hidden_size)\n",
    "        out = self.fc(out[:, -1, :])  # Take last timestep\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eaf03889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MOSTLY_CITED                             [32, 1]                   --\n",
      "├─LSTM: 1-1                              [32, 24, 20]              6,080\n",
      "├─Linear: 1-2                            [32, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 6,101\n",
      "Trainable params: 6,101\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 4.67\n",
      "==========================================================================================\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.18\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = MOSTLY_CITED()\n",
    "print(summary(model, input_size=(32, 24, 12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df67fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels=14, time_steps=24):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=16, kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(16*(time_steps-2), 1)  # -2 because of two conv layers with kernel_size=2\n",
    "        \n",
    "        # Move model to appropriate device\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        # PyTorch expects (batch, channels, seq_len) for Conv1d\n",
    "        x = x.permute(0, 2, 1)  # Change from (batch, seq_len, channels) to (batch, channels, seq_len)\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15ad4f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNLSTMModel                             [32, 1]                   --\n",
      "├─Conv1d: 1-1                            [32, 64, 22]              2,752\n",
      "├─LSTM: 1-2                              [32, 22, 50]              64,000\n",
      "├─Linear: 1-3                            [32, 20]                  1,020\n",
      "├─Linear: 1-4                            [32, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 67,793\n",
      "Trainable params: 67,793\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 47.03\n",
      "==========================================================================================\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.65\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 0.96\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model5 = CNN(input_channels=14, time_steps=24)\n",
    "print(summary(model5, input_size=(32, 24, 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33f8f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=16, hidden_size1=8, hidden_size2=20):\n",
    "        super().__init__()\n",
    "        self.rnn1 = nn.RNN(input_size=input_size, \n",
    "                          hidden_size=hidden_size1,\n",
    "                          batch_first=True,\n",
    "                          nonlinearity='relu')\n",
    "        self.rnn2 = nn.RNN(input_size=hidden_size1,\n",
    "                          hidden_size=hidden_size2,\n",
    "                          batch_first=True,\n",
    "                          nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size2, 1)\n",
    "        \n",
    "        # Move model to appropriate device\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        # First RNN layer (returns all sequences)\n",
    "        x, _ = self.rnn1(x)\n",
    "        # Second RNN layer (returns only last output)\n",
    "        x, _ = self.rnn2(x)\n",
    "        # Take the last time step's output\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6e54011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "RNN                                      [32, 1]                   --\n",
      "├─RNN: 1-1                               [32, 24, 8]               208\n",
      "├─RNN: 1-2                               [32, 24, 20]              600\n",
      "├─Linear: 1-3                            [32, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 829\n",
      "Trainable params: 829\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.62\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.17\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.22\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model2 = RNN(input_size=16)\n",
    "print(summary(model2, input_size=(32, 24, 16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba6a6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.conv1 = nn.Conv1d(in_channels=14, out_channels=64, kernel_size=3).to(self.device)\n",
    "       \n",
    "        self.lstm = nn.LSTM(64, 50, 3, batch_first=True).to(self.device)\n",
    "        self.fc = nn.Linear(50, 20).to(self.device) \n",
    "        self.fc1 = nn.Linear(20, 1).to(self.device) \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x) # _=(h,c)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.fc1(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3ee457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNLSTMModel                             [64, 1]                   --\n",
      "├─Conv1d: 1-1                            [64, 64, 22]              2,752\n",
      "├─LSTM: 1-2                              [64, 22, 50]              64,000\n",
      "├─Linear: 1-3                            [64, 20]                  1,020\n",
      "├─Linear: 1-4                            [64, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 67,793\n",
      "Trainable params: 67,793\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 94.05\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 1.65\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model4 = CNNLSTMModel()\n",
    "print(summary(model4, input_size=(64, 24, 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60398ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMForecastModel(nn.Module):\n",
    "    def __init__(self, time_steps, num_features):\n",
    "        super(LSTMForecastModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=num_features, hidden_size=8, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=8, hidden_size=20, batch_first=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(20, 1)  # final LSTM layer output size is 20\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, time_steps, num_features]\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = x[:, -1, :]  # Take the last time step output\n",
    "        x = self.flatten(x)\n",
    "        out = self.fc(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "652b6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LSTMForecastModel                        [64, 1]                   --\n",
      "├─LSTM: 1-1                              [64, 24, 8]               1,248\n",
      "├─LSTM: 1-2                              [64, 24, 20]              2,400\n",
      "├─Flatten: 1-3                           [64, 20]                  --\n",
      "├─Linear: 1-4                            [64, 1]                   21\n",
      "==========================================================================================\n",
      "Total params: 3,669\n",
      "Trainable params: 3,669\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 5.60\n",
      "==========================================================================================\n",
      "Input size (MB): 0.18\n",
      "Forward/backward pass size (MB): 0.34\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.54\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "time_steps = 24\n",
    "num_features = 29\n",
    "# Instantiate the model\n",
    "model8 = LSTMForecastModel(time_steps, num_features)\n",
    "print(summary(model8, input_size=(64, 24, 29)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7491daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659def4",
   "metadata": {},
   "source": [
    "# instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dbb6ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMForecastModel(\n",
       "  (lstm1): LSTM(29, 8, batch_first=True)\n",
       "  (lstm2): LSTM(8, 20, batch_first=True)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf1f740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MOSTLY_CITED()\n",
    "#model=LSTMForecastModel(time_steps, num_features)\n",
    "#model = RNN(input_size=16)\n",
    "criterion = nn.MSELoss() #Edit, don't change\n",
    "\n",
    "save_best_model = SaveBestModel()\n",
    "Plot_Loss=PlotLossCurves()\n",
    "load_model=LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a217f",
   "metadata": {},
   "source": [
    "# Learning Rate & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f9867523",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001 # Edit\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b55ecf",
   "metadata": {},
   "source": [
    "# Check Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53206b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cpu\n"
     ]
    }
   ],
   "source": [
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device\n",
    "device = get_model_device(model)\n",
    "print(\"Model is on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779171af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8fafebb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa963e",
   "metadata": {},
   "source": [
    "#### Path & other Stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3924df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "num_epochs = 50#Edit\n",
    "best_model_path=r'C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result'+str('\\\\') #Edit\n",
    "fig_path=r'C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result' #Edit\n",
    "train_data_loader, validation_data_loader, test_data_loader = DataLoadeing(train_X ,\n",
    "                                                                           train_y, \n",
    "                                                                           validation_X, \n",
    "                                                                           validation_y, \n",
    "                                                                           test_X, \n",
    "                                                                           test_y, \n",
    "                                                                           batch_size=32) #Batch_Size Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460874b",
   "metadata": {},
   "source": [
    "#### Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2b17e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # Edit, for Now Don't  Change\n",
    "save_best_model = SaveBestModel()\n",
    "Plot_Loss=PlotLossCurves()\n",
    "load_model=LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bee91",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b37aa742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [246/246], Training Loss: 0.0688\n",
      "Epoch [1/50], Step [13/13], Val Loss: 0.0643\n",
      "\n",
      "Saving best model for epoch: 1\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\1best_model.pth\n",
      "Epoch [2/50], Step [246/246], Training Loss: 0.0357\n",
      "Epoch [2/50], Step [13/13], Val Loss: 0.0604\n",
      "\n",
      "Saving best model for epoch: 2\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\2best_model.pth\n",
      "Epoch [3/50], Step [246/246], Training Loss: 0.0323\n",
      "Epoch [3/50], Step [13/13], Val Loss: 0.0601\n",
      "\n",
      "Saving best model for epoch: 3\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\3best_model.pth\n",
      "Epoch [4/50], Step [246/246], Training Loss: 0.0295\n",
      "Epoch [4/50], Step [13/13], Val Loss: 0.0602\n",
      "Epoch [5/50], Step [246/246], Training Loss: 0.0271\n",
      "Epoch [5/50], Step [13/13], Val Loss: 0.0586\n",
      "\n",
      "Saving best model for epoch: 5\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\5best_model.pth\n",
      "Epoch [6/50], Step [246/246], Training Loss: 0.0253\n",
      "Epoch [6/50], Step [13/13], Val Loss: 0.0570\n",
      "\n",
      "Saving best model for epoch: 6\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\6best_model.pth\n",
      "Epoch [7/50], Step [246/246], Training Loss: 0.0242\n",
      "Epoch [7/50], Step [13/13], Val Loss: 0.0562\n",
      "\n",
      "Saving best model for epoch: 7\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\7best_model.pth\n",
      "Epoch [8/50], Step [246/246], Training Loss: 0.0237\n",
      "Epoch [8/50], Step [13/13], Val Loss: 0.0558\n",
      "\n",
      "Saving best model for epoch: 8\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\8best_model.pth\n",
      "Epoch [9/50], Step [246/246], Training Loss: 0.0235\n",
      "Epoch [9/50], Step [13/13], Val Loss: 0.0555\n",
      "\n",
      "Saving best model for epoch: 9\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\9best_model.pth\n",
      "Epoch [10/50], Step [246/246], Training Loss: 0.0234\n",
      "Epoch [10/50], Step [13/13], Val Loss: 0.0553\n",
      "\n",
      "Saving best model for epoch: 10\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\10best_model.pth\n",
      "Epoch [11/50], Step [246/246], Training Loss: 0.0233\n",
      "Epoch [11/50], Step [13/13], Val Loss: 0.0551\n",
      "\n",
      "Saving best model for epoch: 11\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\11best_model.pth\n",
      "Epoch [12/50], Step [246/246], Training Loss: 0.0232\n",
      "Epoch [12/50], Step [13/13], Val Loss: 0.0550\n",
      "\n",
      "Saving best model for epoch: 12\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\12best_model.pth\n",
      "Epoch [13/50], Step [56/246], Training Loss: 0.0237\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9692\\3018697952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_best_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPlot_Loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m       \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m       validation_data_loader)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time Consumed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\shahid\\SHAHID\\stlf_torch_kit.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mstlf_torch_kit.train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SHAHID\\16-Codes\\envs\\STLF\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SHAHID\\16-Codes\\envs\\STLF\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c897f0",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f2d45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d8e071d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 0.001\n",
      "Time Consumed 0.8575103282928467 sec\n",
      "Mean Absolute Error (MAE): 0.42\n",
      "Median Absolute Error (MedAE): 0.36\n",
      "Mean Squared Error (MSE): 0.26\n",
      "Root Mean Squared Error (RMSE): 0.51\n",
      "Mean Absolute Percentage Error (MAPE): 87.14 %\n",
      "Median Absolute Percentage Error (MDAPE): 48.89 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (413, 1)\n",
      "y_pred.shape=  (413, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\12best_model.pth' # Edit\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results( scaler, y_pred_scaled,test_y)\n",
    "\n",
    "# MAPE, MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ed24f",
   "metadata": {},
   "source": [
    "# Fine Tunning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "42338ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lr=0.0001\n",
    "Batch_size = True #batch size maintained\n",
    "load_model_path=r'C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\12best_model.pth' # Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaffc7c",
   "metadata": {},
   "source": [
    "#### Load Model for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2d00f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 0.0001\n"
     ]
    }
   ],
   "source": [
    "if Batch_size is True:\n",
    "    model_, optimizer, start_epoch= load_model(model, model_path=load_model_path,\n",
    "                               lr=lr,\n",
    "                               train_X=train_X,\n",
    "                               train_y=train_y,\n",
    "                               validation_X=validation_X,\n",
    "                               validation_y=validation_y,\n",
    "                               test_X=test_X,\n",
    "                               test_y=test_y)\n",
    "\n",
    "else:\n",
    "    model_, optimizer, start_epoch, train_data_loader, validation_data_loader, test_data_loader = load_model(model,model_path=load_model_path,\n",
    "                                                                                             lr=lr,\n",
    "                                                                                             Batch_Size=32,\n",
    "                                                                                             train_X=train_X,\n",
    "                                                                                             train_y=train_y,\n",
    "                                                                                             validation_X=validation_X,\n",
    "                                                                                             validation_y=validation_y,\n",
    "                                                                                             test_X=test_X,\n",
    "                                                                                             test_y=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3e7d8432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/112], Step [1/246], Training Loss: 0.0667\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/112], Step [246/246], Training Loss: 0.0244\n",
      "Epoch [13/112], Step [13/13], Val Loss: 0.0529\n",
      "\n",
      "Saving best model for epoch: 13\n",
      " at C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\13best_model.pth\n",
      "Epoch [14/112], Step [30/246], Training Loss: 0.0342\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9692\\1954758671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m       \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m       \u001b[0mvalidation_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m      load_model_epoch=start_epoch)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time Consumed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\shahid\\SHAHID\\stlf_torch_kit.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mstlf_torch_kit.train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SHAHID\\16-Codes\\envs\\STLF\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9692\\1750017246.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Move input to same device as model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# out shape: (batch, seq_len, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Take last timestep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SHAHID\\16-Codes\\envs\\STLF\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SHAHID\\16-Codes\\envs\\STLF\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 775\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_)\n",
    "start = time.time()\n",
    "\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader,\n",
    "     load_model_epoch=start_epoch)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19971578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 0.0001\n",
      "Time Consumed 0.5225558280944824 sec\n",
      "Mean Absolute Error (MAE): 0.37\n",
      "Median Absolute Error (MedAE): 0.27\n",
      "Mean Squared Error (MSE): 0.24\n",
      "Root Mean Squared Error (RMSE): 0.49\n",
      "Mean Absolute Percentage Error (MAPE): 59.97 %\n",
      "Median Absolute Percentage Error (MDAPE): 39.58 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (413, 1)\n",
      "y_pred.shape=  (413, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'C:\\Users\\SHAHID\\shahid (ML-lab)\\pro_result\\11best_model.pth'\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b5c72",
   "metadata": {},
   "source": [
    "# Fine Tunning 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8855adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 0.00001\n",
    "Batch_size=32\n",
    "load_model_path=r'D:\\chk6\\88best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1a0f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n"
     ]
    }
   ],
   "source": [
    "if Batch_size is True:\n",
    "    model_, optimizer, start_epoch= load_model(model, model_path=load_model_path,\n",
    "                               lr=lr,\n",
    "                               train_X=train_X,\n",
    "                               train_y=train_y,\n",
    "                               validation_X=validation_X,\n",
    "                               validation_y=validation_y,\n",
    "                               test_X=test_X,\n",
    "                               test_y=test_y)\n",
    "\n",
    "else:\n",
    "    model_, optimizer, start_epoch, train_data_loader, validation_data_loader, test_data_loader = load_model(model,model_path=load_model_path,\n",
    "                                                                                             lr=lr,\n",
    "                                                                                             Batch_Size=Batch_size,\n",
    "                                                                                             train_X=train_X,\n",
    "                                                                                             train_y=train_y,\n",
    "                                                                                             validation_X=validation_X,\n",
    "                                                                                             validation_y=validation_y,\n",
    "                                                                                             test_X=test_X,\n",
    "                                                                                             test_y=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfc79445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/108], Step [2653/2653], Training Loss: 0.0001\n",
      "Epoch [89/108], Step [758/758], Val Loss: 0.0001\n",
      "Epoch [90/108], Step [2653/2653], Training Loss: 0.0001\n",
      "Epoch [90/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 90\n",
      " at D:\\chk6\\90best_model.pth\n",
      "Epoch [91/108], Step [2653/2653], Training Loss: 0.0001\n",
      "Epoch [91/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 91\n",
      " at D:\\chk6\\91best_model.pth\n",
      "Epoch [92/108], Step [2653/2653], Training Loss: 0.0001\n",
      "Epoch [92/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 92\n",
      " at D:\\chk6\\92best_model.pth\n",
      "Epoch [93/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [93/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 93\n",
      " at D:\\chk6\\93best_model.pth\n",
      "Epoch [94/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [94/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 94\n",
      " at D:\\chk6\\94best_model.pth\n",
      "Epoch [95/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [95/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 95\n",
      " at D:\\chk6\\95best_model.pth\n",
      "Epoch [96/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [96/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 96\n",
      " at D:\\chk6\\96best_model.pth\n",
      "Epoch [97/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [97/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 97\n",
      " at D:\\chk6\\97best_model.pth\n",
      "Epoch [98/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [98/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 98\n",
      " at D:\\chk6\\98best_model.pth\n",
      "Epoch [99/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [99/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 99\n",
      " at D:\\chk6\\99best_model.pth\n",
      "Epoch [100/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [100/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 100\n",
      " at D:\\chk6\\100best_model.pth\n",
      "Epoch [101/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [101/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 101\n",
      " at D:\\chk6\\101best_model.pth\n",
      "Epoch [102/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [102/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 102\n",
      " at D:\\chk6\\102best_model.pth\n",
      "Epoch [103/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [103/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 103\n",
      " at D:\\chk6\\103best_model.pth\n",
      "Epoch [104/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [104/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 104\n",
      " at D:\\chk6\\104best_model.pth\n",
      "Epoch [105/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [105/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 105\n",
      " at D:\\chk6\\105best_model.pth\n",
      "Epoch [106/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [106/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 106\n",
      " at D:\\chk6\\106best_model.pth\n",
      "Epoch [107/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [107/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 107\n",
      " at D:\\chk6\\107best_model.pth\n",
      "Epoch [108/108], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [108/108], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 108\n",
      " at D:\\chk6\\108best_model.pth\n",
      "Time Consumed 252.91170525550842 sec\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_)\n",
    "start = time.time()\n",
    "\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader,\n",
    "     load_model_epoch=start_epoch)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "403a487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n",
      "Time Consumed 0.29328155517578125 sec\n",
      "Mean Absolute Error (MAE): 91.01\n",
      "Median Absolute Error (MedAE): 71.54\n",
      "Mean Squared Error (MSE): 14858.5\n",
      "Root Mean Squared Error (RMSE): 121.9\n",
      "Mean Absolute Percentage Error (MAPE): 0.62 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.5 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (12105, 1)\n",
      "y_pred.shape=  (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'D:\\chk6\\108best_model.pth'\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2db74c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "#lr = 0.0001\n",
    "Batch_size=32\n",
    "load_model_path=r'D:\\chk6\\108best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dab68625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n"
     ]
    }
   ],
   "source": [
    "if Batch_size is True:\n",
    "    model_, optimizer, start_epoch= load_model(model, model_path=load_model_path,\n",
    "                               lr=lr,\n",
    "                               train_X=train_X,\n",
    "                               train_y=train_y,\n",
    "                               validation_X=validation_X,\n",
    "                               validation_y=validation_y,\n",
    "                               test_X=test_X,\n",
    "                               test_y=test_y)\n",
    "\n",
    "else:\n",
    "    model_, optimizer, start_epoch, train_data_loader, validation_data_loader, test_data_loader = load_model(model,model_path=load_model_path,\n",
    "                                                                                             lr=lr,\n",
    "                                                                                             Batch_Size=Batch_size,\n",
    "                                                                                             train_X=train_X,\n",
    "                                                                                             train_y=train_y,\n",
    "                                                                                             validation_X=validation_X,\n",
    "                                                                                             validation_y=validation_y,\n",
    "                                                                                             test_X=test_X,\n",
    "                                                                                             test_y=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba9a314b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [109/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 109\n",
      " at D:\\chk6\\109best_model.pth\n",
      "Epoch [110/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [110/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 110\n",
      " at D:\\chk6\\110best_model.pth\n",
      "Epoch [111/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [111/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 111\n",
      " at D:\\chk6\\111best_model.pth\n",
      "Epoch [112/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [112/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 112\n",
      " at D:\\chk6\\112best_model.pth\n",
      "Epoch [113/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [113/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 113\n",
      " at D:\\chk6\\113best_model.pth\n",
      "Epoch [114/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [114/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 114\n",
      " at D:\\chk6\\114best_model.pth\n",
      "Epoch [115/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [115/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 115\n",
      " at D:\\chk6\\115best_model.pth\n",
      "Epoch [116/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [116/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 116\n",
      " at D:\\chk6\\116best_model.pth\n",
      "Epoch [117/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [117/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 117\n",
      " at D:\\chk6\\117best_model.pth\n",
      "Epoch [118/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [118/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 118\n",
      " at D:\\chk6\\118best_model.pth\n",
      "Epoch [119/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [119/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 119\n",
      " at D:\\chk6\\119best_model.pth\n",
      "Epoch [120/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [120/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 120\n",
      " at D:\\chk6\\120best_model.pth\n",
      "Epoch [121/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [121/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 121\n",
      " at D:\\chk6\\121best_model.pth\n",
      "Epoch [122/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [122/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 122\n",
      " at D:\\chk6\\122best_model.pth\n",
      "Epoch [123/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [123/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 123\n",
      " at D:\\chk6\\123best_model.pth\n",
      "Epoch [124/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [124/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 124\n",
      " at D:\\chk6\\124best_model.pth\n",
      "Epoch [125/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [125/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 125\n",
      " at D:\\chk6\\125best_model.pth\n",
      "Epoch [126/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [126/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 126\n",
      " at D:\\chk6\\126best_model.pth\n",
      "Epoch [127/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [127/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 127\n",
      " at D:\\chk6\\127best_model.pth\n",
      "Epoch [128/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [128/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 128\n",
      " at D:\\chk6\\128best_model.pth\n",
      "Epoch [129/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [129/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 129\n",
      " at D:\\chk6\\129best_model.pth\n",
      "Epoch [130/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [130/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 130\n",
      " at D:\\chk6\\130best_model.pth\n",
      "Epoch [131/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [131/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 131\n",
      " at D:\\chk6\\131best_model.pth\n",
      "Epoch [132/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [132/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 132\n",
      " at D:\\chk6\\132best_model.pth\n",
      "Epoch [133/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [133/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 133\n",
      " at D:\\chk6\\133best_model.pth\n",
      "Epoch [134/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [134/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 134\n",
      " at D:\\chk6\\134best_model.pth\n",
      "Epoch [135/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [135/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 135\n",
      " at D:\\chk6\\135best_model.pth\n",
      "Epoch [136/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [136/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 136\n",
      " at D:\\chk6\\136best_model.pth\n",
      "Epoch [137/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [137/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 137\n",
      " at D:\\chk6\\137best_model.pth\n",
      "Epoch [138/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [138/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 138\n",
      " at D:\\chk6\\138best_model.pth\n",
      "Epoch [139/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [139/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 139\n",
      " at D:\\chk6\\139best_model.pth\n",
      "Epoch [140/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [140/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 140\n",
      " at D:\\chk6\\140best_model.pth\n",
      "Epoch [141/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [141/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 141\n",
      " at D:\\chk6\\141best_model.pth\n",
      "Epoch [142/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [142/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 142\n",
      " at D:\\chk6\\142best_model.pth\n",
      "Epoch [143/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [143/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 143\n",
      " at D:\\chk6\\143best_model.pth\n",
      "Epoch [144/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [144/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 144\n",
      " at D:\\chk6\\144best_model.pth\n",
      "Epoch [145/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [145/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 145\n",
      " at D:\\chk6\\145best_model.pth\n",
      "Epoch [146/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [146/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 146\n",
      " at D:\\chk6\\146best_model.pth\n",
      "Epoch [147/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [147/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 147\n",
      " at D:\\chk6\\147best_model.pth\n",
      "Epoch [148/148], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [148/148], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 148\n",
      " at D:\\chk6\\148best_model.pth\n",
      "Time Consumed 570.459014415741 sec\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_)\n",
    "start = time.time()\n",
    "\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader,\n",
    "     load_model_epoch=start_epoch)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e08ead66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n",
      "Time Consumed 0.7108466625213623 sec\n",
      "Mean Absolute Error (MAE): 90.44\n",
      "Median Absolute Error (MedAE): 70.79\n",
      "Mean Squared Error (MSE): 14699.12\n",
      "Root Mean Squared Error (RMSE): 121.24\n",
      "Mean Absolute Percentage Error (MAPE): 0.62 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.49 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (12105, 1)\n",
      "y_pred.shape=  (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'D:\\chk6\\148best_model.pth'\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6930fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85d1b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "#lr = 0.00001\n",
    "Batch_size=32\n",
    "load_model_path=r'D:\\chk6\\148best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "261fc4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n"
     ]
    }
   ],
   "source": [
    "if Batch_size is True:\n",
    "    model_, optimizer, start_epoch= load_model(model, model_path=load_model_path,\n",
    "                               lr=lr,\n",
    "                               train_X=train_X,\n",
    "                               train_y=train_y,\n",
    "                               validation_X=validation_X,\n",
    "                               validation_y=validation_y,\n",
    "                               test_X=test_X,\n",
    "                               test_y=test_y)\n",
    "\n",
    "else:\n",
    "    model_, optimizer, start_epoch, train_data_loader, validation_data_loader, test_data_loader = load_model(model,model_path=load_model_path,\n",
    "                                                                                             lr=lr,\n",
    "                                                                                             Batch_Size=Batch_size,\n",
    "                                                                                             train_X=train_X,\n",
    "                                                                                             train_y=train_y,\n",
    "                                                                                             validation_X=validation_X,\n",
    "                                                                                             validation_y=validation_y,\n",
    "                                                                                             test_X=test_X,\n",
    "                                                                                             test_y=test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52effded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [149/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 149\n",
      " at D:\\chk6\\149best_model.pth\n",
      "Epoch [150/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [150/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 150\n",
      " at D:\\chk6\\150best_model.pth\n",
      "Epoch [151/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [151/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 151\n",
      " at D:\\chk6\\151best_model.pth\n",
      "Epoch [152/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [152/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 152\n",
      " at D:\\chk6\\152best_model.pth\n",
      "Epoch [153/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [153/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 153\n",
      " at D:\\chk6\\153best_model.pth\n",
      "Epoch [154/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [154/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 154\n",
      " at D:\\chk6\\154best_model.pth\n",
      "Epoch [155/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [155/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 155\n",
      " at D:\\chk6\\155best_model.pth\n",
      "Epoch [156/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [156/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 156\n",
      " at D:\\chk6\\156best_model.pth\n",
      "Epoch [157/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [157/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 157\n",
      " at D:\\chk6\\157best_model.pth\n",
      "Epoch [158/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [158/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 158\n",
      " at D:\\chk6\\158best_model.pth\n",
      "Epoch [159/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [159/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 159\n",
      " at D:\\chk6\\159best_model.pth\n",
      "Epoch [160/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [160/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 160\n",
      " at D:\\chk6\\160best_model.pth\n",
      "Epoch [161/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [161/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 161\n",
      " at D:\\chk6\\161best_model.pth\n",
      "Epoch [162/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [162/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 162\n",
      " at D:\\chk6\\162best_model.pth\n",
      "Epoch [163/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [163/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 163\n",
      " at D:\\chk6\\163best_model.pth\n",
      "Epoch [164/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [164/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 164\n",
      " at D:\\chk6\\164best_model.pth\n",
      "Epoch [165/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [165/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 165\n",
      " at D:\\chk6\\165best_model.pth\n",
      "Epoch [166/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [166/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 166\n",
      " at D:\\chk6\\166best_model.pth\n",
      "Epoch [167/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [167/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 167\n",
      " at D:\\chk6\\167best_model.pth\n",
      "Epoch [168/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [168/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 168\n",
      " at D:\\chk6\\168best_model.pth\n",
      "Epoch [169/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [169/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 169\n",
      " at D:\\chk6\\169best_model.pth\n",
      "Epoch [170/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [170/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 170\n",
      " at D:\\chk6\\170best_model.pth\n",
      "Epoch [171/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [171/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 171\n",
      " at D:\\chk6\\171best_model.pth\n",
      "Epoch [172/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [172/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 172\n",
      " at D:\\chk6\\172best_model.pth\n",
      "Epoch [173/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [173/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 173\n",
      " at D:\\chk6\\173best_model.pth\n",
      "Epoch [174/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [174/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 174\n",
      " at D:\\chk6\\174best_model.pth\n",
      "Epoch [175/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [175/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 175\n",
      " at D:\\chk6\\175best_model.pth\n",
      "Epoch [176/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [176/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 176\n",
      " at D:\\chk6\\176best_model.pth\n",
      "Epoch [177/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [177/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 177\n",
      " at D:\\chk6\\177best_model.pth\n",
      "Epoch [178/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [178/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 178\n",
      " at D:\\chk6\\178best_model.pth\n",
      "Epoch [179/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [179/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 179\n",
      " at D:\\chk6\\179best_model.pth\n",
      "Epoch [180/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [180/188], Step [758/758], Val Loss: 0.0001\n",
      "Epoch [181/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [181/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 181\n",
      " at D:\\chk6\\181best_model.pth\n",
      "Epoch [182/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [182/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 182\n",
      " at D:\\chk6\\182best_model.pth\n",
      "Epoch [183/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [183/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 183\n",
      " at D:\\chk6\\183best_model.pth\n",
      "Epoch [184/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [184/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 184\n",
      " at D:\\chk6\\184best_model.pth\n",
      "Epoch [185/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [185/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 185\n",
      " at D:\\chk6\\185best_model.pth\n",
      "Epoch [186/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [186/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 186\n",
      " at D:\\chk6\\186best_model.pth\n",
      "Epoch [187/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [187/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 187\n",
      " at D:\\chk6\\187best_model.pth\n",
      "Epoch [188/188], Step [2653/2653], Training Loss: 0.0000\n",
      "Epoch [188/188], Step [758/758], Val Loss: 0.0001\n",
      "\n",
      "Saving best model for epoch: 188\n",
      " at D:\\chk6\\188best_model.pth\n",
      "Time Consumed 522.1760857105255 sec\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_)\n",
    "start = time.time()\n",
    "\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader,\n",
    "     load_model_epoch=start_epoch)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "989a1be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 1e-05\n",
      "Time Consumed 0.32709288597106934 sec\n",
      "Mean Absolute Error (MAE): 90.16\n",
      "Median Absolute Error (MedAE): 70.6\n",
      "Mean Squared Error (MSE): 14619.34\n",
      "Root Mean Squared Error (RMSE): 120.91\n",
      "Mean Absolute Percentage Error (MAPE): 0.61 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.49 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (12105, 1)\n",
      "y_pred.shape=  (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'D:\\chk6\\188best_model.pth'\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STLF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
